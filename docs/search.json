[
  {
    "objectID": "Teaching/ME200.html",
    "href": "Teaching/ME200.html",
    "title": "ME200 (Computational Methods in Financial Mathematics)",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInternet is a great resource. Use it. Some resources I like:\n\nMIT OpenCourseWare,\nStanford,\nHarvard.\n\n\n\n\n\n\n\n\n\n\nBeware, the Crime!\n\n\n\nIt is illegal to download articles and books from pages like LibGen, Sci-hub or from Telegram bots like @scihubot. Also, DO NOT use VPN to protect your freedom of education (Opera offers a free VPN).\n\n🙃\n\n\n\n\n\n\nCourse content (Official)\n\n\nMethods for generating samples from a given probability distribution,\nMonte Carlo estimation,\nVariance reduction techniques,\nThe binomial asset pricing model and the concept of no-arbitrage,\nThe Black-Scholes option pricing model as a limit of the binomial model,\nApplication of Monte Carlo methods to pricing financial derivatives,\nIntroduction to programming in Python,\nIntroduction to option pricing with multiple periods in financial markets.\n\n\nLecture Notes\n\nPlease ask for lecture notes and solutions to the teachers of this course."
  },
  {
    "objectID": "Teaching/ST455.html",
    "href": "Teaching/ST455.html",
    "title": "ST455 (Reinforcement Learning)",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInternet is a great resource. Use it. Some resources I like:\n\nMIT OpenCourseWare,\nStanford,\nHarvard.\n\n\n\n\n\n\n\n\n\n\nBeware, the Crime!\n\n\n\nIt is illegal to download articles and books from pages like LibGen, Sci-hub or from Telegram bots like @scihubot. Also, DO NOT use VPN to protect your freedom of education (Opera offers a free VPN).\n\n🙃\n\n\n\n\n\n\nCourse content (Official)\n\nThis course is about reinforcement learning, covering the fundamental concepts of reinforcement learning framework and solution methods. The focus is on the underlying methodology as well as practical implementation and evaluation using software code. The course will cover the following topics:\n\nIntroduction: course overview.\nFoundations of reinforcement learning: Markov decision process, Bellman optimality equation, the existence of optimal stationary policy\nDynamic programing and Monte Carlo methods: policy evaluation, policy improvement, policy iteration, value iteration based on dynamic programming, and Monte Carlo methods for reinforcement learning, including Monte Carlo estimation and Monte Carlo control.\nTemporal difference learning: temporal difference learning, temporal difference prediction, Sarsa, Q-learning and n-step temporal difference predictions, TD(lambda).\nOn-policy prediction and control with approximation: types of function approximators (value and action-value function approximator), gradient based methods for value function prediction, convergence guarantees with linear function approximator, and semi-gradient n-step Sarsa.\nQ-learning type algorithms with function approximation: q-learning with linear function approximator, fitted q-iteration, deep q-network, double deep q-learning, convergence analysis.\nPolicy gradient methods: policy approximation, REINFORCE, actor-critic methods that combine policy function approximation with action-value function approximation.\nTrust-region policy optimization: monotonic improvement guarantee, trust-region policy optimization.\nBatch off-policy evaluation: importance sampling-based method, doubly robust method, marginalized importance sampling, double reinforcement learning.\nBatch policy optimisation: recent advances in offline reinforcement learning algorithms.\n\n\nMaterial and solutions\n\nThe material followed very closely the content of the famous book by Sutton and Barto."
  },
  {
    "objectID": "Teaching/MA210.html",
    "href": "Teaching/MA210.html",
    "title": "MA210 (Discrete Mathematics)",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInternet is a great resource. Use it. Some resources I like:\n\nMIT OpenCourseWare,\nStanford,\nHarvard.\n\n\n\n\n\n\n\n\n\n\nBeware, the Crime!\n\n\n\nIt is illegal to download articles and books from pages like LibGen, Sci-hub or from Telegram bots like @scihubot. Also, DO NOT use VPN to protect your freedom of education (Opera offers a free VPN).\n\n🙃\n\n\n\n\n\n\nCourse content (Official)\n\nThis is a course covering a number of concepts and techniques of discrete mathematics. Topics covered: Counting: selections; inclusion-exclusion; generating functions; recurrence relations. Graph Theory: basic concepts; walks, paths, tours and cycles; trees and forests; colourings. Coding theory: basic concepts; linear codes.\n\nMaterial (Official and mine)\n\nHere are some notes I took during the course and that helped me teach it.\n\n\n\nWeek\nNotes\n\n\n\n\nWeek 1\nNotes\n\n\nWeek 2\nNotes\n\n\nWeek 3\nNotes\n\n\nWeek 4\nNotes\n\n\nWeek 5\nNotes\n\n\nWeek 6\nNotes\n\n\nWeek 7\nNotes\n\n\nWeek 8\nNotes\n\n\nWeek 9\nNotes"
  },
  {
    "objectID": "Teaching/MA423.html",
    "href": "Teaching/MA423.html",
    "title": "MA423 (Fundamentals of Operations Research)",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInternet is a great resource. Use it. Some resources I like:\n\nMIT OpenCourseWare,\nStanford,\nHarvard.\n\n\n\n\n\n\n\n\n\n\nBeware, the Crime!\n\n\n\nIt is illegal to download articles and books from pages like LibGen, Sci-hub or from Telegram bots like @scihubot. Also, DO NOT use VPN to protect your freedom of education (Opera offers a free VPN).\n\n🙃\n\n\n\n\n\nThis file is all I have left from what I prepared for this course. I shall be more careful in keeping my documents in the future.\n\nCourse content (Official)\n\nAn introduction to a range of Operations Research techniques, covering: foundations of linear programming, including the simplex method and duality; integer programming; markov chains; queueing theory; dynamic programming; deterministic and stochastic inventory models; game theory."
  },
  {
    "objectID": "Teaching/Pre-sessionals/Stats3.html",
    "href": "Teaching/Pre-sessionals/Stats3.html",
    "title": "Pre-sessionals - Stats 3",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInternet is a great resource. Use it. Some resources I like:\n\nMIT OpenCourseWare,\nStanford,\nHarvard.\n\n\n\n\n\n\n\n\n\n\nBeware, the Crime!\n\n\n\nIt is illegal to download articles and books from pages like LibGen, Sci-hub or from Telegram bots like @scihubot. Also, DO NOT use VPN to protect your freedom of education (Opera offers a free VPN).\n\n🙃\n\n\n\n\n\n\nProbability and Reading Table\n\n\nIntroduction to Probability\n\nBasic Concepts of Probability\n\nDefine probability as the measure of likelihood of an event.\nIntroduce the concept of sample space and events.\nExample: Tossing a fair coin as a simple probability experiment.\n\nProbability as a Ratio\n\nExplain how probability is calculated as a ratio of favorable outcomes to total outcomes.\nDiscuss the range of probability from 0 to 1.\nExercise: Calculate the probability of rolling a specific number on a fair six-sided die.\n\nProbability vs. Odds\n\nDefine odds as the ratio of favorable outcomes to unfavorable outcomes.\nCompare and contrast probability and odds.\nExample: Compare the probability and odds of drawing a red card from a deck.\n\n\nProbability Distributions\n\nDiscrete vs. Continuous Probability Distributions\n\nDifferentiate between discrete and continuous random variables.\nDiscuss examples of each type of distribution.\nExercise: Identify whether given scenarios involve discrete or continuous random variables.\n\nProbability Mass Function (PMF) and Probability Density Function (PDF)\n\nExplain the concepts of PMF for discrete distributions and PDF for continuous distributions.\nDiscuss how they represent probabilities of specific outcomes and ranges.\nExample: Calculate and interpret the PMF of a binomial distribution.\nExercise: Determine the PDF of a given continuous distribution.\n\nExamples of Uniform, Binomial, and Normal Distributions\n\nIntroduce uniform, binomial, and normal distributions.\nExplain scenarios where each distribution is applicable.\nExample: Describe the characteristics of a normal distribution.\nExercise: Identify situations where specific distributions might be observed.\n\n\nReading Data Tables\n\nUnderstanding Data Tables and Formats\n\nDefine data tables as organized representations of data.\nExplain columns, rows, and headings in data tables.\nExercise: Interpret the structure of a given data table.\n\nExtracting Information from Frequency Tables\n\nDiscuss frequency tables and their role in summarizing categorical data.\nExplain how to calculate relative frequencies and percentages from frequency tables.\nExample: Calculate relative frequencies from a frequency table of survey responses.\nExercise: Calculate relative frequencies for various categories in a given frequency table.\n\nInterpreting Data Presented in Tabular Form\n\nGuide students in extracting meaningful insights from data tables.\nDiscuss patterns, trends, and comparisons that can be made using data tables.\nExample: Interpret a frequency table of ages in a population.\nExercise: Analyze and draw conclusions from a provided data table.\n\n\nConclusion and Recap\n\nSummarize the key concepts covered in the lecture.\n\nQ&A Session\nReference: Statistics for Business, 2nd edition. R. A. Stine, D. Foster"
  },
  {
    "objectID": "Teaching/Pre-sessionals/Stats1.html",
    "href": "Teaching/Pre-sessionals/Stats1.html",
    "title": "Pre-sessionals - Stats 1",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInternet is a great resource. Use it. Some resources I like:\n\nMIT OpenCourseWare,\nStanford,\nHarvard.\n\n\n\n\n\n\n\n\n\n\nBeware, the Crime!\n\n\n\nIt is illegal to download articles and books from pages like LibGen, Sci-hub or from Telegram bots like @scihubot. Also, DO NOT use VPN to protect your freedom of education (Opera offers a free VPN).\n\n🙃\n\n\n\n\n\n\nIntroduction to Basic Statistics\n\n\nIntroduction to Statistics\n\nWhat is Statistics and its Importance\n\nDefine statistics as the study of data collection, analysis, and interpretation.\nExplain the importance of statistics in decision-making and research.\nExample: Discuss how statistics are used in medical research.\n\nDescriptive vs. Inferential Statistics\n\nDifferentiate between descriptive and inferential statistics.\nEmphasize the role of each in understanding and drawing conclusions from data.\nExercise: Provide scenarios and determine whether descriptive or inferential statistics would be used.\n\nTypes of Data: Categorical and Numerical\n\nExplain the distinction between categorical and numerical data.\nProvide examples of each type of data.\nExercise: Classify given data sets as categorical or numerical.\n\n\nMeasures of Central Tendency\n\nMean, Median, and Mode\n\nDefine and explain the concepts of mean, median, and mode.\nIllustrate how to calculate each measure.\nExample: Calculate mean, median, and mode for a set of exam scores.\nExercise: Compute mean, median, and mode for different data sets.\n\nCalculating and Interpreting Each Measure\n\nDiscuss the interpretation of mean, median, and mode in terms of centrality.\nHighlight scenarios where each measure is useful.\nExercise: Analyze the implications of outliers on measures of central tendency.\n\nReal-World Examples\n\nProvide real-world examples where mean, median, and mode are applied.\nDiscuss their relevance in various contexts, such as finance or education.\nExercise: Analyze a dataset from a real-world scenario and calculate central tendency measures.\n\n\nMeasures of Dispersion\n\nRange, Variance, and Standard Deviation\n\nDefine and explain the concepts of range, variance, and standard deviation.\nDemonstrate how to calculate each measure.\nExample: Calculate the range, variance, and standard deviation for a data set.\nExercise: Compute range, variance, and standard deviation for different datasets.\n\nInterpreting Variability\n\nDiscuss the importance of measures of dispersion in understanding data spread.\nExplain how variability affects the interpretation of central tendency measures.\nExercise: Compare and contrast datasets with different measures of dispersion.\n\nVariance and Standard Deviation for Populations vs. Samples\n\nExplain the difference between calculating variance and standard deviation for populations and samples.\nDiscuss when to use the population formula versus the sample formula.\nExample: Calculate the population and sample variance and standard deviation for a dataset.\n\n\nQuantiles and Percentiles\n\nDefinition of Quantiles and Percentiles\n\nDefine quantiles and percentiles as measures of position in a dataset.\nExplain how they divide data into equal parts.\nExercise: Calculate the quartiles and percentiles for a dataset.\n\nCalculation and Interpretation\n\nDiscuss how to calculate quantiles and percentiles using order statistics.\nInterpret the meaning of specific quantiles and percentiles.\nExample: Calculate the interquartile range and 75th percentile for a dataset.\nExercise: Calculate and interpret quantiles and percentiles for various datasets.\n\nBox Plots and Their Use in Visualizing Quantiles\n\nExplain how box plots represent the five-number summary and outliers.\nDiscuss the components of a box plot (whiskers, box, median, outliers).\nExample: Create a box plot for a dataset and analyze its features.\nExercise: Construct box plots for given datasets and identify characteristics.\n\n\nConclusion and Recap\n\nSummarize the key concepts covered in the lecture.\n\nQ&A Session\nReference: Statistics for Business, 2nd edition. R. A. Stine, D. Foster"
  },
  {
    "objectID": "Teaching/Pre-sessionals/Maths1.html",
    "href": "Teaching/Pre-sessionals/Maths1.html",
    "title": "Pre-sessionals - Maths 1",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInternet is a great resource. Use it. Some resources I like:\n\nMIT OpenCourseWare,\nStanford,\nHarvard.\n\n\n\n\n\n\n\n\n\n\nBeware, the Crime!\n\n\n\nIt is illegal to download articles and books from pages like LibGen, Sci-hub or from Telegram bots like @scihubot. Also, DO NOT use VPN to protect your freedom of education (Opera offers a free VPN).\n\n🙃\n\n\n\n\n\n\nIntroduction to Functions and Linear Equations\n\n\nIntroduction to Functions\n\nWhat is a function?\n\nDefinition: A function is a relation between a set of inputs (domain) and a set of possible outputs (range), such that each input is related to exactly one output.\nExample: Temperature conversion function.\nExercise: Identify whether given relations are functions or not.\n\nDomain and Range of a function\n\nDefinition of domain and range.\nExample: Find the domain and range of the function \\(f(x) = \\sqrt{x}\\).\nExercise: Determine the domain and range of a given function.\n\nNotation and Terminology\n\nNotation: \\(f(x)\\) represents the output of function \\(f\\) for input \\(x\\).\nTerminology: Input, output, independent variable, dependent variable, etc.\nExercise: Translate word problems into function notation.\n\n\nLinear Functions\n\nDefinition of Linear Functions\n\nA linear function is a function whose graph is a straight line.\nExample: \\(f(x) = 2x + 3\\) is a linear function.\nExercise: Determine whether given functions are linear or not.\n\nGraphing Linear Functions\n\nPlotting points and connecting with a line.\nExample: Graph the function \\(f(x) = -0.5x + 2\\).\nExercise: Graph a set of linear functions.\n\nSlope and \\(y\\)-Intercept\n\nDefinition of slope and \\(y\\)-intercept.\nCalculation of slope and \\(y\\)-intercept from an equation.\nExample: Find the slope and \\(y\\)-intercept of \\(f(x) = 3x - 1\\).\nExercise: Calculate slope and \\(y\\)-intercept of given functions.\n\n\nPolynomial Functions of Degree 2\n\nDefinition of Polynomial Functions\n\nA polynomial function is a function consisting of terms with non-negative integer powers.\nExample: \\(f(x) = 2x^2 - 4x + 1\\) is a polynomial function.\nExercise: Identify polynomial functions among given expressions.\n\nQuadratic Functions\n\nDefinition and standard form: \\(f(x) = ax^2 + bx + c\\).\nExample: Identify coefficients of \\(a\\), \\(b\\), and \\(c\\) in \\(f(x) = 5x^2 - 2x + 7\\).\nExercise: Write quadratic functions in standard form.\n\nGraphing Quadratic Functions\n\nPlotting quadratic curves.\nFinding vertex and axis of symmetry.\nExample: Graph \\(f(x) = x^2 - 4x + 3\\) and find its vertex.\nExercise: Graph given quadratic functions and locate their vertices.\n\n\nApplications of Functions\n\nReal-World Examples of Functions\n\nDistance-time and temperature-time functions.\nExample: Express the height of an object in terms of time.\nExercise: Identify functions in everyday scenarios.\n\nModeling with Linear and Quadratic Functions\n\nUsing linear functions for proportional relationships.\nUsing quadratic functions for parabolic motion.\nExample: Model the height of a ball thrown vertically upward.\nExercise: Model a real-world scenario using a linear or quadratic function.\n\nSimple Problems Involving Functions\n\nSolving basic problems using functions.\nExample: Find the time when a car reaches a certain distance.\nExercise: Solve problems involving linear and quadratic functions.\n\n\nConclusion and Recap\n\nSummarize the key concepts covered in the lecture.\nHighlight the importance of functions in various fields.\n\nQ&A Session\nExercises\nReferences"
  },
  {
    "objectID": "Teaching/Pre-sessionals/Maths3.html",
    "href": "Teaching/Pre-sessionals/Maths3.html",
    "title": "Pre-sessionals - Maths 3",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInternet is a great resource. Use it. Some resources I like:\n\nMIT OpenCourseWare,\nStanford,\nHarvard.\n\n\n\n\n\n\n\n\n\n\nBeware, the Crime!\n\n\n\nIt is illegal to download articles and books from pages like LibGen, Sci-hub or from Telegram bots like @scihubot. Also, DO NOT use VPN to protect your freedom of education (Opera offers a free VPN).\n\n🙃\n\n\n\n\n\n\nSystems of Linear Equations\n\n\nIntroduction to Systems of Equations\n\nWhat is a System of Equations?\n\nDefinition of a system of equations as a set of equations with common variables.\nExample: Discuss a system representing the total cost of items purchased.\n\nMethods for Solving Systems\n\nBriefly explain graphing, substitution, and elimination methods.\nHighlight when each method is most suitable.\nExercise: Identify which method is best for a given system.\n\nImportance and Applications\n\nEmphasize the significance of systems of equations in solving real-world problems.\nMention applications in various fields.\nExercise: Brainstorm other scenarios where systems could be applied.\n\n\nGraphical Solution\n\nSolving Systems Graphically\n\nExplain the concept of solution points as intersections of graphs.\nExample: Solve the system \\(2x + y = 5\\) and \\(3x -y = 1\\) graphically.\nExercise: Graph and solve simple systems of equations.\n\nInterpreting Solutions on Graphs\n\nDiscuss the significance of unique solutions, no solutions, and infinite solutions.\nInterpret the graphical meaning of these cases.\nExercise: Analyze different scenarios on graphs.\n\nAdvantages and Limitations\n\nCompare graphical method with other methods.\nDiscuss accuracy and limitations of graphical solutions.\n\n\nSubstitution and Elimination Methods\n\nSolving Systems using Substitution\n\nExplain the substitution method step by step.\nExample: Solve the system \\(3x -2y = 8\\) and \\(x + y = 3\\) using substitution.\nExercise: Practice solving systems using the substitution method.\n\nSolving Systems using Elimination\n\nExplain the elimination (addition) method step by step.\nExample: Solve the system \\(2x + 3y = 7\\) and \\(4x -y = 5\\) using elimination.\nExercise: Practice solving systems using the elimination method.\n\n\nApplications of Systems of Equations\n\nReal-World Examples of Systems\n\nDiscuss examples from fields like economics, chemistry, and engineering.\nExample: Discuss a mixture problem involving two solutions.\nExercise: Brainstorm more real-world examples.\n\nUsing Systems to Solve Practical Problems\n\nExplain how to set up and solve practical problems using systems.\nExample: Solve a money-related problem involving different types of coins.\nExercise: Solve practical problems related to mixtures, interest, or other scenarios.\n\nReflection on Problem-Solving\n\nHighlight the problem-solving process and the role of systems.\nEncourage students to think critically and apply these methods.\n\n\nConclusion and Recap\n\nSummarize the key concepts covered in the lecture.\n\nQ&A Session\nExercises\nReferences"
  },
  {
    "objectID": "Teaching/Teaching.html",
    "href": "Teaching/Teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "These pages contain some of the material I used to aid my teaching during my years at LSE. Some of the material I created myself, some was given by the various lecturers of the courses, some I found online and I propose here again in a selected format.\nFor a quick overview of my teaching, you can consult the following table.\n\nCourses taught\n\n\n\n\n\n\n\n\n\nCode\nName\nYear(s)\nDepartment\nMain Lecturer\n\n\n\n\nMA102/3\nIntroduction to Abstract Mathematics\n2020/21; 21/22\nMaths\nPeter Allen\n\n\nME306\nReal Analysis\n2021\nMaths\nJohannes Ruf\n\n\nMA210\nDiscrete Mathematics\n2021/22\nMaths\nPeter Allen\n\n\nMA423\nFundamentals of Operations Research\n2021/22\nMaths\nAhmad Abdi\n\n\nME200\nComputational Methods in Financial Mathematics\n2023\nMaths\nLuitgard Veraart\n\n\nST310\nMachine Learning\n2022/23\nStats\nJoshua Loftus\n\n\nST455\nReinforcement Learning\n2022/23\nStats\nChengchun Shi\n\n\nFM250\nFinance\n2023\nFinance\nAshwini Agrawal\n\n\nPR\nMiM/GMiM pre-sessionals\n2022; 23\nManag.\nMyself\n\n\n\nFor privacy reasons, I won’t add my students’ feedbacks in this page. If you are interested in additional information about my teaching, please contact me.",
    "crumbs": [
      "Teaching"
    ]
  },
  {
    "objectID": "Learning/Learning.html",
    "href": "Learning/Learning.html",
    "title": "Learning",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\nThe goal of this section is to collect resources and thougths, and to record my learning progresses regarding topics I am not proficient in, mainly Competitive Coding, Machine Learning, Reinforcement Learning.\nThese are my main motivations behind this decision.\n\nI did not find online any resource tailored to my need,\nI hope this might help other people to get close to these topics,\nThe best way to learn is to teach.\n\n Caveat: I know Python is NOT the best language for competitive coding, but since my objective for now is not perfection, I will mainly use Python for now. \nPlease do let me know if you find any mistakes.",
    "crumbs": [
      "Learning"
    ]
  },
  {
    "objectID": "Learning/Python/Useful/Greatest_authors.html",
    "href": "Learning/Python/Useful/Greatest_authors.html",
    "title": "Greatest Authors",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\nI appreciate a lot this project by Shane Sherman, which is an attempt to create a list of “best books” based on the compound information found on various highly accredited lists (there are obvious critiques, about western, white, male biases etc., but I don’t think this is relevant in the context of this page). What I am going to do in this page is to have an idea of which authors have more works considered the best.\nOne can proceed as follows: download the .csv file from the website of the aforementioned project. Modify the .csv file such that the first row reads:\n\n\n\nPosition\nTitle\nAuthor\nYear\n\n\n\n\n\nIn the same folder where you saved the .csv file, you can create a .py file with the following code.\n1import pandas as pd\n\n2df = pd.read_csv(\"tgb_1.csv\")\nmylist = df[\"Author\"]\n\n3splittings = [100, 500, 1000, len(mylist)]\nN = len(splittings)\nPartial_lists = [mylist[:i] for i in splittings]\n\n4Counts = [pd.Series(Partial_lists[j]).value_counts() for j in range(N)]\n\n5Lower = [0 for i in range(N)]\nAt_least = 10\nfor i in range(N):\n    for j in range(30, -1, -1):\n        if len(Counts[i][Counts[i]&gt;=j])&gt;=At_least:\n            Lower[i]=j\n            break\nFinal_list_authors = [Counts[i][Counts[i]&gt;=Lower[i]] for i in range(N)]\n\n6for i in range(N):\n    print(\"These are the authors that have the most (at least \"+str(Lower[i])+\") publications\\namongst the first \"+str(splittings[i])+\"\"\" many \"Best books\" \"\"\")\n    print(Final_list_authors[i].to_string()+\"\\n\")\n\n1\n\nImport the pandas library. Useful for statistics.\n\n2\n\nRead the .csv file and save in a pandas array the column with header Author (this is why a modification of the file was necessary).\n\n3\n\nWe create 4 lists. The first analyses the first 100 books, the second the first 500 books and so on. Partial_lists is a list that contains in entry i a pandas list with the authors of the first splittings[i]-many books.\n\n4\n\nWe count the occurrencies in each of the partial lists.\n\n5\n\nWe select in each list Partial_lists[i] the first authors. These are the authors that have at least Lower[i] many books in that list. Lower[i] is choosen in such a way that the authors as as few as possible above At_least. So for example in the first list, if we set Lower[0]=3 we would only obtain 5 authors, this is why we set Lower[0]=2.\n\n6\n\nPrinting.\n\n\nThe output is:\nThese are the authors that have the most (at least 2) publications\namongst the first 100 many \"Best books\" \nErnest Hemingway      4\nFranz Kafka           4\nFyodor Dostoyevsky    4\nWilliam Faulkner      3\nVirginia Woolf        3\nVladimir Nabokov      2\nSophocles             2\nJames Joyce           2\nStendhal              2\nCharles Dickens       2\nJane Austen           2\nGeorge Orwell         2\nGustave Flaubert      2\nHomer                 2\nLeo Tolstoy           2\n\nThese are the authors that have the most (at least 4) publications\namongst the first 500 many \"Best books\" \nSophocles              7\nCharles Dickens        7\nErnest Hemingway       6\nWilliam Shakespeare    6\nC. S. Lewis            6\nJohn Galsworthy        5\nAeschylus              5\nFyodor Dostoyevsky     5\nSamuel Beckett         4\nJohn Updike            4\nSaul Bellow            4\nHonoré de Balzac       4\nWilliam Faulkner       4\nJoseph Conrad          4\nVirginia Woolf         4\nEdith Wharton          4\nJohn Dos Passos        4\nD. H. Lawrence         4\nThomas Mann            4\nJames Joyce            4\nFranz Kafka            4\n\nThese are the authors that have the most (at least 6) publications\namongst the first 1000 many \"Best books\" \nWilliam Shakespeare    11\nCharles Dickens         9\nWilliam Faulkner        9\nSamuel Beckett          8\nSophocles               7\nJ. K Rowling            7\nC. S. Lewis             6\nPhilip Roth             6\nHenry James             6\nErnest Hemingway        6\n\nThese are the authors that have the most (at least 8) publications\namongst the first 2706 many \"Best books\" \nWilliam Shakespeare    19\nWilliam Faulkner       13\nCharles Dickens        13\nUnknown                11\nHenry James            11\nIris Murdoch           10\nMargaret Atwood        10\nPhilip Roth            10\nJohn Updike             8\nSamuel Beckett          8\nErnest Hemingway        8\nJ M Coetzee             8\nMolière                 8\nAlice Munro             8\nFaulkner, Hemingway and Dickens are the only authors present in all 4 lists. Sheakerspeare appears in all the list with the exception of the first one, and has 1.5 times the second author (Faulkner and Dickens) books in the complete list, while Sophocles is also doing quite well. The only women appearing are Virginia Woold, Jane Austen, Edith Wharton, J.K. Rowling, Iris Murdoch, Margaret Atwood and Alice Munro; with Woolf and Austen being the only ones in the first list.\nChatGPT is a mess, but it seems that the only author not born in Europe (including Russia) or US/Canada is Coetzee (South Africa). This seems to indicate that these lists are incredibly biased.\nFor more analysis, you can try to run this for a more complete print.\nfor i in range(N):\n    print(\"#\"*77+\"\\nThese are the authors that have the most (at least \"+str(Lower[i])+\") publications\\namongst the first \"+str(splittings[i])+\"\"\" many \"Best books\"\\n\"\"\"+\"#\"*77)\n    for j, A in zip(Final_list_authors[i], Final_list_authors[i].index):\n        print(\"%\"*77+\"\\n\"+A + \" (\"+str(j)+\")\")\n        L=df[:splittings[i]][df[:splittings[i]][\"Author\"]==A][\"Title\"]\n        Num=df[:splittings[i]][df[:splittings[i]][\"Author\"]==A][\"Number\"]\n        Num=list(Num)\n        T=list(L)\n        for k in range(len(Num)):\n            print(\"\\t\", str(int(Num[k]))+\" \", \"\\t\", T[k])\n        print(\"%\"*77+\"\\n\")\n    print(\"\\n\\n\")\nAn example of the first part of the output is:\n#############################################################################\nThese are the authors that have the most (at least 2) publications\namongst the first 100 many \"Best books\"\n############################################################################# \n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nErnest Hemingway (4)\n     44      The Sun Also Rises \n     57      The Old Man and the Sea\n     60      For Whom the Bell Tolls\n     84      A Farewell to Arms\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nFranz Kafka (4)\n     33      The Trial\n     61      The Complete Stories of Franz Kafka\n     62      The Metamorphosis\n     86      The Castle\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nFyodor Dostoyevsky (4)\n     13      The Brothers Karamazov \n     14      Crime and Punishment \n     54      The Idiot\n     69      The Possessed\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nWilliam Faulkner (3)\n     25      The Sound and the Fury\n     30      Absalom, Absalom!\n     67      As I Lay Dying\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nVirginia Woolf (3)\n     22      To the Lighthouse \n     38      Mrs. Dalloway \n     79      Orlando: A Biography\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nVladimir Nabokov (2)\n     12      Lolita \n     65      Pale Fire \n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nSophocles (2)\n     51      Oedipus the King\n     66      Antigone\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nJames Joyce (2)\n     2       Ulysses\n     49      A Portrait of the Artist as a Young Man \n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nStendhal (2)\n     34      The Red and the Black\n     93      The Charterhouse of Parma\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nCharles Dickens (2)\n     27      Great Expectations\n     45      David Copperfield\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nJane Austen (2)\n     17      Pride and Prejudice\n     59      Emma\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nGeorge Orwell (2)\n     26      Nineteen Eighty Four\n     78      Animal Farm\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nGustave Flaubert (2)\n     10      Madame Bovary\n     87      A Sentimental Education\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nHomer (2)\n     9       The Odyssey\n     21      The Iliad\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nLeo Tolstoy (2)\n     7       War and Peace\n     19      Anna Karenina\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%",
    "crumbs": [
      "Learning",
      "Python",
      "Useful",
      "Greatest Authors"
    ]
  },
  {
    "objectID": "Learning/Python/Papers/SBRD.html",
    "href": "Learning/Python/Papers/SBRD.html",
    "title": "Utility functions (please skip to the next section)",
    "section": "",
    "text": "import numpy as np\nimport math\nimport matplotlib.pyplot as plt\nfrom time import time\nimport scipy.stats as stats\nfrom scipy.stats import beta\nfrom functools import reduce\nfrom operator import matmul\ndef softmax(r):\n# Define a softmax function.\n    exp_r = np.exp(r - np.max(r))\n    return exp_r / np.sum(exp_r)\n\ndef gradient_ascent_dynamics(G, n, eta=1.0, max_iter=50_000, T_max=10): \n# The following function implements a (softmax) gradient ascent algorithm for a 3-player game with n actions.\n# It takes the number of actions n, a correlation parameter lam, a learning rate eta, a max iteration count,\n# and a tolerance for convergence as inputs. It returns the average payoff, the number of iterations,\n# and the final payoff for player 0.    \n    t_0 = time()\n    # Initialise each player's \"logit\" vector (which will be mapped to a mixed strategy via softmax).\n    r0 = np.zeros(n)\n    r1 = np.zeros(n)\n    r2 = np.zeros(n)\n    \n    total_payoff = 0.0\n    \n    for it in range(max_iter):\n        # Convert logits to mixed strategies.\n        p0 = softmax(r0)\n        p1 = softmax(r1)\n        p2 = softmax(r2)\n\n        \n        # Compute the expected payoff for each pure action for each player.\n        # For player 0: Q0[i] = sum_{j,k} p1[j] p2[k] G[0][i, j, k]\n        Q0 = np.array([np.dot(p1, np.dot(G[0][i, :n, :n], p2)) for i in range(n)])\n        # For player 1: Q1[i] = sum_{j,k} p0[j] p2[k] G[1][j, i, k]\n        Q1 = np.array([np.dot(p0, np.dot(G[1][:n, i, :n], p2)) for i in range(n)])\n        # For player 2: Q2[i] = sum_{j,k} p0[j] p1[k] G[2][j, k, i]\n        Q2 = np.array([np.dot(p0, np.dot(G[2][:n, :n, i], p1)) for i in range(n)])\n        \n        # Compute the overall expected payoff for each player.\n        f0 = np.dot(p0, Q0)\n        f1 = np.dot(p1, Q1)\n        f2 = np.dot(p2, Q2)\n        \n        # Accumulate payoff for averaging.\n        total_payoff += f0\n\n        # Every 100 iterations, check if the current strategy profile is an epsilon-NE.\n        if it % 100 == 0:\n            best0 = np.max(Q0)\n            best1 = np.max(Q1)\n            best2 = np.max(Q2)\n            if ((f0 &gt;= 0.99 * best0) and (f1 &gt;= 0.99 * best1) and (f2 &gt;= 0.99 * best2)) or (time()-t_0 &gt; T_max):\n                break\n\n\n        grad_r0 = Q0 - f0\n        grad_r1 = Q1 - f1\n        grad_r2 = Q2 - f2\n        \n        # Update the logits using a simple gradient ascent step.\n        r0 += eta * grad_r0 \n        r1 += eta * grad_r1 \n        r2 += eta * grad_r2 \n    \n    avg_payoff = total_payoff / it\n    return it, avg_payoff, f0\n\n\n# Hyperparameters for gradient ascent. These numbers have been selected after some trial and error, and provided the best results for this algorithm.\nstep_size = 1.0\nmax_iterations = 50_000\nThese are utility function only used to plot\ndef clopper_pearson_interval(k, n, alpha=0.005):\n    lower = beta.ppf(alpha / 2, k, n - k + 1) if k &gt; 0 else 0.0\n    upper = beta.ppf(1 - alpha / 2, k + 1, n - k) if k &lt; n else 1.0\n    return lower, upper\n\ndef plot_single_algorithm(alg_name=\"SBRD\", varName=\"time\", ylabel=None, axis=0, mean_name=None, variance=True, only_if_conv=False, log=False, n_cols=1, number_of_plots=-1, binomial=False, isPositive=False, width=6, legend_loc = \"upper left\", title=None):\n    \"\"\"\n    Plot runtimes of a single algorithm (PGD or SBRD) in subplots, comparing across one parameter.\n\n    Parameters:\n    - alg_name: 'PGD' or 'SBRD'\n    - varName: variable name suffix for accessing data (e.g., \"Seconds\" accesses PGD_Seconds or SBRD_Seconds)\n    - axis: 0 or 1\n        - 0: compare across N for each Lambda (row-wise)\n        - 1: compare across Lambda for each N (column-wise)\n    - variance: whether to include standard deviation shading\n    - only_if_conv: whether to only include data when convergence was achieved (using *_isNash)\n    - log: whether to plot on a log scale\n    - n_cols: number of columns of subplots to create\n    - number_of_plots: number of subplots to show (-1 for all)\n    - lambda_vals: optional list/array of Lambda values\n    - A_vals: optional list/array of N values\n    - binomial: whether the data is binomial (0-1 values)\n    \"\"\"\n\n    if ylabel == None:\n        ylabel = varName\n\n    # If the function input \"only_if_conv\" is True, only include the cases in which the samples for which algorithm converges\n    data = globals()[f\"{alg_name}_{varName}\"]\n    if only_if_conv:\n        isNash = globals()[f\"{alg_name}_isNash\"]\n        masked_data = np.where(isNash, data, np.nan)\n    else:\n        masked_data = data\n\n    \"\"\"\n    Creates the matrix of means and the matrices needed for the Confidence Intervals.\n    If the data is Binary, the CI is done using the Clopper Pearson interval. If the data is real, we use the Standard Error\n    \"\"\"\n\n    mean_data = np.nanmean(masked_data, axis=-1)\n    if variance:\n        n_data = np.sum(~np.isnan(masked_data), axis=-1)\n        if binomial:\n            sum_data = np.nansum(masked_data, axis=-1)\n            lower_bounds = np.zeros_like(mean_data)\n            upper_bounds = np.ones_like(mean_data)\n            for i in range(mean_data.shape[0]):\n                for j in range(mean_data.shape[1]):\n                    if n_data[i, j] &gt; 0:\n                        lower, upper = clopper_pearson_interval(int(sum_data[i, j]), int(n_data[i, j]))\n                        lower_bounds[i, j] = lower\n                        upper_bounds[i, j] = upper\n        else:\n            SE_data = np.sqrt(np.divide(np.nanvar(masked_data, axis=-1), n_data))\n\n    L, N = mean_data.shape\n\n    \"\"\" \n    Depending on wether we want the plots to be done along the 0 or 1 axis, we get different \"get_mean\", \"get_lower\" and \"get_upper\"\n    functions, that take as input i and return the right vector (respectively the mean, lower and upper CI points) with that index.\n    \"\"\"\n    if axis == 0:\n        num_plots = L\n        x_vals = A_vals \n        y_vals = lambda_vals \n        get_mean = lambda i: mean_data[i, :]\n        if variance:\n            if binomial:\n                get_lower = lambda i: lower_bounds[i, :]\n                get_upper = lambda i: upper_bounds[i, :]\n            else:\n                get_var = lambda i: SE_data[i, :]\n        label = \"Correlation λ\"\n        xlabel = \"Nr. actions\"\n    elif axis == 1:\n        num_plots = N\n        x_vals = lambda_vals\n        y_vals = A_vals \n        get_mean = lambda i: mean_data[:, i]\n        if variance:\n            if binomial:\n                get_lower = lambda i: lower_bounds[:, i]\n                get_upper = lambda i: upper_bounds[:, i]\n            else:\n                get_var = lambda i: SE_data[:, i]\n        label = \"Nr. actions\"\n        xlabel = \"Correlation λ\"\n    else:\n        raise ValueError(\"Axis must be 0 (over Lambda) or 1 (over N)\")\n    \n\n\n    \"\"\"\n    We now create the structure for the plots\n    \"\"\"\n    if number_of_plots == -1 or number_of_plots &gt;= num_plots:\n        indices = list(range(num_plots))\n    else:\n        indices = np.linspace(0, num_plots - 1, number_of_plots, dtype=int)\n\n    n_rows = math.ceil(len(indices) / n_cols)\n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(width * n_cols, 3 * n_rows), sharex=True)\n    axes = np.array(axes).flatten()\n\n    color = (0.1, 0.5, 0.8) if alg_name == \"PGD\" else (0.9, 0.4, 0.2)\n\n    \"\"\"\n    We finally plot the various graphs\n    \"\"\"\n\n    for i, idx in enumerate(indices):\n        ax = axes[i]\n        ax.set_xlabel(xlabel)\n        if log:\n            ax.set_yscale('log')\n            ydata = get_mean(idx)\n            ymin = np.nanmin(ydata)\n            ymax = np.nanmax(ydata)\n\n            # Round to nearest powers of 10\n            lower = 10 ** np.floor(np.log10(ymin))\n            upper = 10 ** np.ceil(np.log10(ymax))\n            ax.set_ylim(lower, upper)\n        ax.plot(x_vals, get_mean(idx), color=color, label=mean_name if mean_name!= None else varName)\n        if variance:\n            if binomial:\n                ax.fill_between(x_vals, get_lower(idx), get_upper(idx), color=color, alpha=0.2, label='99.5% CI')\n            else:\n                if isPositive:\n                    lower = np.clip(get_mean(idx) - 2*get_var(idx), 0, None)\n                    upper = np.clip(get_mean(idx) + 2*get_var(idx), 0, None)\n                ax.fill_between(x_vals, lower, upper, color=color, alpha=0.2, label='±2 SE')\n        ax.set_ylabel(ylabel)\n        if title == None:\n            ax.set_title(f\"{label} = {round(y_vals[idx], 2)}, samples = {samples}\")\n        else:\n            ax.set_title(title)\n        ax.legend(loc=legend_loc)\n        ax.grid(True)\n\n    for j in range(len(indices), len(axes)):\n        fig.delaxes(axes[j])\n\n    plt.tight_layout(rect=[0, 0, 1, 0.96])\n    plt.savefig(f\"{alg_name}_{varName}_samples={samples} axis={axis}.pdf\")\n    plt.show()\n\n\n\ndef compare_algorithms(PGD_varName=\"time\", SBRD_varName=\"time\", yLabel=None, axis=0, mean_1_name=None, mean_2_name=None, title=None, variance=True, only_if_conv=False, log=False, n_cols=1, number_of_plots=-1, binomial=False, width = 6, isPositive=False, legend_loc=\"upper left\"):\n    \"\"\"\n    Plot runtimes of PGD and SBRD algorithms in subplots, comparing them across one parameter.\n\n    Parameters:\n    - PGD_varName, SBRD_varName: variable name suffix for accessing data (e.g., \"time\" accesses PGD_time and SBRD_time)\n    - axis: 0 or 1\n        - 0: compare across N for each Lambda (row-wise)\n        - 1: compare across Lambda for each N (column-wise)\n    - variance: whether to include standard deviation shading\n    - only_if_conv: whether to only include data when convergence was achieved (using PGD_isNash, SBRD_isNash)\n    - log: whether to plot on a log scale\n    - n_cols: number of columns of subplots to create\n    - lambda_vals: global list/array of Lambda values\n    - A_vals: global list/array of N values\n    - number_of_plots: number of subplots to display (equally spaced). If -1, show all.\n    - binomial: whether the data is binomial (0-1)\n    - isPositive: whether to clip the lower bound at 0\n    \"\"\"\n    if yLabel == None:\n        yLabel = PGD_varName\n\n    def process_data(alg_name, varName):\n        data = globals()[f\"{alg_name}_{varName}\"]\n        if only_if_conv:\n            isNash = globals()[f\"{alg_name}_S7_isNash\"]\n            data = np.where(isNash, data, np.nan)\n        mean_data = np.nanmean(data, axis=-1)\n        n_data = np.sum(~np.isnan(data), axis=-1)\n\n        if not variance:\n            return mean_data, None, None\n\n        if binomial:\n            sum_data = np.nansum(data, axis=-1)\n            lower_bounds = np.zeros_like(mean_data)\n            upper_bounds = np.ones_like(mean_data)\n            for i in range(mean_data.shape[0]):\n                for j in range(mean_data.shape[1]):\n                    if n_data[i, j] &gt; 0:\n                        lower, upper = clopper_pearson_interval(int(sum_data[i, j]), int(n_data[i, j]))\n                        lower_bounds[i, j] = lower\n                        upper_bounds[i, j] = upper\n            return mean_data, lower_bounds, upper_bounds\n        else:\n            SE = np.sqrt(np.nanvar(data, axis=-1) / n_data)\n            lower_bounds = mean_data - 2 * SE\n            upper_bounds = mean_data + 2 * SE\n            return mean_data, lower_bounds, upper_bounds\n\n    PGD_mean, PGD_lower, PGD_upper = process_data(\"PGD\", PGD_varName)\n    SBRD_mean, SBRD_lower, SBRD_upper = process_data(\"SBRD\", SBRD_varName)\n\n    L, N = PGD_mean.shape\n    if axis == 0:\n        num_plots = L\n        x_vals = A_vals\n        y_vals = lambda_vals\n        get_slice = lambda data, i: data[i, :]\n        label = \"Correlation λ\"\n        xlabel = \"Nr. actions\"\n    elif axis == 1:\n        num_plots = N\n        x_vals = lambda_vals\n        y_vals = A_vals\n        get_slice = lambda data, i: data[:, i]\n        label = \"Nr. actions\"\n        xlabel = \"Correlation λ\"\n    else:\n        raise ValueError(\"Axis must be 0 (over Lambda) or 1 (over N)\")\n\n    indices = range(num_plots) if number_of_plots == -1 or number_of_plots &gt;= num_plots else np.linspace(0, num_plots - 1, number_of_plots, dtype=int)\n    n_rows = math.ceil(len(indices) / n_cols)\n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(width * n_cols, 3 * n_rows), sharex=True)\n    axes = np.array(axes).flatten()\n\n    colors = {\"PGD\": (0.1, 0.5, 0.8), \"SBRD\": (0.9, 0.4, 0.2)}\n\n    for i, idx in enumerate(indices):\n        ax = axes[i]\n        ax.set_xlabel(xlabel)\n        if log:\n            ax.set_yscale('log')\n\n        for name, mean, lower, upper, color in [\n            (\"PGD\", PGD_mean, PGD_lower, PGD_upper, colors[\"PGD\"]),\n            (\"SBRD\", SBRD_mean, SBRD_lower, SBRD_upper, colors[\"SBRD\"])\n        ]:\n            y = get_slice(mean, idx)\n            if variance:\n                if binomial:\n                    if name == \"PGD\":\n                        curr_label = mean_1_name\n                    if name == \"SBRD\":\n                        curr_label = mean_2_name\n                else:\n                    if name == \"PGD\":\n                        curr_label = mean_1_name\n                    if name == \"SBRD\":\n                        curr_label = mean_2_name\n            ax.plot(x_vals, y, label=curr_label, color=color)\n            if variance and lower is not None and upper is not None:\n                y_lower = get_slice(lower, idx)\n                y_upper = get_slice(upper, idx)\n                if isPositive:\n                    y_lower = np.clip(y_lower, 0, None)\n                    y_upper = np.clip(y_upper, 0, None)\n                #label_ci = \"99.5% CI\" if binomial else \"±2SE\"\n                ax.fill_between(x_vals, y_lower, y_upper, color=color, alpha=0.2)#, label=f\"{label_ci}\")\n\n        ax.set_ylabel(yLabel)\n        if title == None:\n            ax.set_title(f\"{label} = {round(y_vals[idx], 2)}, samples = {samples}\")\n        else:\n            ax.set_title(title)\n        ax.legend(loc= legend_loc)\n        ax.grid(True)\n\n    for j in range(len(indices), len(axes)):\n        fig.delaxes(axes[j])\n\n    plt.tight_layout(rect=[0, 0, 1, 0.96])\n    plt.savefig(f\"compare_{PGD_varName}_axis={axis}.pdf\")\n    plt.show()"
  },
  {
    "objectID": "Learning/Python/Papers/SBRD.html#dynamics-definitions",
    "href": "Learning/Python/Papers/SBRD.html#dynamics-definitions",
    "title": "Utility functions (please skip to the next section)",
    "section": "Dynamics definitions",
    "text": "Dynamics definitions\n\ndef generate_reward_matrix(P, A, lam):\n    \"\"\"\n    Generate the reward matrix for an P-player A-actions game \n\n    Parameters:\n    - N (int): Number of actions per player.\n    - lam (float): Correlation between players' payoffs.\n\n    Returns:\n    - np.ndarray: Reward tensor G of shape (3, N, N, N). Each entry G[i, a, b, c]\n      is the payoff for player i when players 1, 2, 3 play actions a, b, c respectively.\n    \"\"\"\n    # Correlation matrix across players\n    diagonal = np.diag(np.ones(P))\n    ones_matrix = np.ones((P, P))\n    corr_matrix = (ones_matrix-np.diag(np.diag(ones_matrix)))*lam+diagonal\n    \n    # Cholesky decomposition for generating correlated normal variables\n    L = np.linalg.cholesky(corr_matrix)\n    \n    # Generate correlated payoffs for all joint action profiles\n    raw_samples = np.random.randn(P, A**P)\n    correlated = L @ raw_samples\n    \n    shape = tuple(P if i==0 else A for i in range(P+1))\n\n    # Reshape to (3, N, N, N): one payoff matrix per player\n    return correlated.reshape(shape)\n\n\ndef best_response_dynamics(G, A=None):\n    \"\"\"\n    Simulate Best Response Dynamics (SBRD) in a 3-player game.\n\n    Parameters:\n    - G (np.ndarray): Reward tensor of shape (3, N, N, N). G[i, a, b, c] gives the payoff\n      to player i when players 0, 1, 2 choose actions a, b, c respectively.\n\n    Returns:\n    - cycle_length (int): Length of the cycle detected by SBRD.\n    - total_steps (int): Total number of steps before entering the cycle.\n    - final_payoff (float): Average payoff for player 0 over the detected cycle.\n    \"\"\"\n    P = G.shape[0]\n    if A == None:\n        A = G.shape[1]\n\n    x = tuple(0 for _ in range(P))        # Initial strategy profile\n    index = 0                             # Step counter\n    history = dict()                      # Maps strategy profiles to step indices\n\n    while True:\n        index += 1\n\n        # Best responses given others' actions\n        x = tuple( np.argmax( G[ tuple(i if j == 0 else x[j-1] if j-1 != i else slice(0, A) for j in range(P+1)) ] ) for i in range(P))\n\n\n        if x in history:\n            cycle_length = index - history[x]\n\n            if cycle_length == 1:\n                # Nash Equilibria\n                return cycle_length, index, G[tuple(0 if i == 0 else x[i-1] for i in range(P+1))]\n\n            # General cycle detected: compute average payoff for player 0\n            cycle = [x]\n            avg = G[tuple(0 if i == 0 else x[i-1] for i in range(P+1))]\n\n            for _ in range(cycle_length - 1):\n                x = tuple( np.argmax( G[ tuple(i if j == 0 else x[j-1] if j-1 != i else slice(0, A) for j in range(P+1)) ] ) for i in range(P))\n                cycle.append(x)\n                avg += G[tuple(0 if i == 0 else x[i-1] for i in range(P+1))]\n\n            return cycle_length, index, avg / cycle_length\n\n        # Log the current profile and continue\n        history[x] = index\n\n\ndef softmax(r):\n# Define a softmax function.\n    exp_r = np.exp(r - np.max(r))\n    return exp_r / np.sum(exp_r)\n\n\ndef new_SPGD(G, eta=1.0, max_iter=50_000, T_max=10): \n# The following function implements a (softmax) gradient ascent algorithm for a 3-player game with n actions.\n# It takes the number of actions n, a correlation parameter lam, a learning rate eta, a max iteration count,\n# and a tolerance for convergence as inputs. It returns the average payoff, the number of iterations,\n# and the final payoff for player 0.    \n    t_0 = time()\n    # Initialise each player's \"logit\" vector (which will be mapped to a mixed strategy via softmax).\n    P, A = G.shape[0:2]\n\n    R = tuple(np.zeros(A) for _ in range(P))\n    \n    total_payoff = 0.0\n    n=A\n    p=[3 for i in range(P)]\n    for it in range(max_iter):\n        # Convert logits to mixed strategies.\n        Softmax = tuple(softmax(R[i]) for i in range(P))\n        \n        # Compute the expected payoff for each pure action for each player.\n        # For player 0: Q0[i] = sum_{j,k} p1[j] p2[k] G[0][i, j, k]\n  \n        Q = tuple(                       # Q[0], …, Q[P-1]\n            np.array([               #   each is an (A, …, A) tensor\n                np.take(G[p], i, axis=p)              # fix the i-th action of player p\n                @ reduce(matmul,                     # multiply all the other Softmax mats\n                        (Softmax[j] for j in range(P) if j != p))\n            for i in range(A)])\n        for p in range(P))\n\n\n        # For player 1: Q1[i] = sum_{j,k} p0[j] p2[k] G[1][j, i, k]\n        \n        # Compute the overall expected payoff for each player.\n        F = tuple(np.dot(Softmax[i], Q[i]) for i in range(P))\n        \n        # Accumulate payoff for averaging.\n        total_payoff += F[0]\n\n        # Every 100 iterations, check if the current strategy profile is an epsilon-NE.\n        if it % 100 == 0:\n            best = tuple(np.max(Q[i]) for i in range(P))\n            if (min(best)&gt;0.99) or (time()-t_0 &gt; T_max):\n                break\n\n\n        grad = tuple(Q[i]-F[i] for i in range(P))\n        \n        # Update the logits using a simple gradient ascent step.\n        R = tuple(R[i]+eta*grad[i] for i in range(P))\n    \n    avg_payoff = total_payoff / it\n    return it, avg_payoff, F[0]"
  },
  {
    "objectID": "Learning/Python/Papers/SBRD.html#section-1.-finding-2-player-random-potential-games-converge-fast-to-a-two-cycle",
    "href": "Learning/Python/Papers/SBRD.html#section-1.-finding-2-player-random-potential-games-converge-fast-to-a-two-cycle",
    "title": "Utility functions (please skip to the next section)",
    "section": "Section 1. Finding: 2-player random potential games converge fast to a two-cycle",
    "text": "Section 1. Finding: 2-player random potential games converge fast to a two-cycle\n\n# Number of simulations per (λ, N) setting\nsamples = 10_000\nlambda_vals = [0.09999999999*0.5*i for i in range(21)]\nA_vals = [50]\n\nSBRD_S1_twoCycles = np.full((len(lambda_vals), 1, samples), False, dtype=bool)\nSBRD_S1_nrSteps = np.zeros((len(lambda_vals), len(A_vals), samples))\n\n\nnp.random.seed(2025) #We set the random seed for reproducibility \nT_0 = time()  # Start timer for entire experiment\nmax_A = max(A_vals)\nfor count_lam, lam in enumerate(lambda_vals):  # Loop over each lambda value\n    for i in range(samples):  # Repeat experiment for statistical robustness\n        G = generate_reward_matrix(2, max_A, lam)  # Generate a payoff matrix with max_n actions and correlation lambda\n    \n        for count_A, A in enumerate(A_vals):  # Now restrict to smaller N if needed\n            # Run Best Response Dynamics and time it\n            SBRD_len, SBRD_it, SBRD_val_curr = best_response_dynamics(G, A)\n            SBRD_S1_twoCycles[count_lam, count_A, i] = (SBRD_len == 2)\n            SBRD_S1_nrSteps[count_lam, count_A, i] = SBRD_it\n\n# Final time report\nTotal_time = time() - T_0\nprint(Total_time)\n\n22.372665882110596\n\n\n\nplot_single_algorithm(alg_name=\"SBRD\", varName=\"S1_twoCycles\", title=\"\", mean_name=\"A\", ylabel=\"Prob. conver. to two-cycle\", axis=1, binomial=True, legend_loc=\"upper left\")\n\n\n\n\n\n\n\n\n\nplot_single_algorithm(alg_name=\"SBRD\", varName=\"S1_nrSteps\", mean_name=\"nrSteps\", title=\"\", ylabel=\"Steps\", axis=1, isPositive=True, log=False, legend_loc=\"upper right\")\n\n\n\n\n\n\n\n\n\nprint(round(lambda_vals[int(np.argmax(np.mean(SBRD_S1_twoCycles, axis=-1)&gt;0.5))],2))\nprint(round(lambda_vals[int(np.argmax(np.mean(SBRD_S1_twoCycles, axis=-1)&gt;0.9))],2))\n\n0.55\n0.9"
  },
  {
    "objectID": "Learning/Python/Papers/SBRD.html#section-2.-finding-3-player-random-potential-games-converge-fast-to-a-ne",
    "href": "Learning/Python/Papers/SBRD.html#section-2.-finding-3-player-random-potential-games-converge-fast-to-a-ne",
    "title": "Utility functions (please skip to the next section)",
    "section": "Section 2. Finding: 3-player random potential games converge fast to a NE",
    "text": "Section 2. Finding: 3-player random potential games converge fast to a NE\n\n# Number of simulations per (λ, N) setting\nsamples = 10_000\nlambda_vals = [0.09999999999*0.5*i for i in range(21)]\nA_vals = [50]\n\nSBRD_S2_isNash = np.full((len(lambda_vals), 1, samples), False, dtype=bool)\nSBRD_S2_nrSteps = np.zeros((len(lambda_vals), len(A_vals), samples))\n\n\nnp.random.seed(2025) #We set the random seed for reproducibility \nT_0 = time()  # Start timer for entire experiment\nmax_A = max(A_vals)\nfor count_lam, lam in enumerate(lambda_vals):  # Loop over each lambda value\n    for i in range(samples):  # Repeat experiment for statistical robustness\n        G = generate_reward_matrix(3, max_A, lam)  # Generate a payoff matrix with max_n actions and correlation lambda\n    \n        for count_A, A in enumerate(A_vals):  # Now restrict to smaller N if needed\n            # Run Best Response Dynamics and time it\n            SBRD_len, SBRD_it, SBRD_val_curr = best_response_dynamics(G, A)\n            SBRD_S2_isNash[count_lam, count_A, i] = (SBRD_len == 1)\n            SBRD_S2_nrSteps[count_lam, count_A, i] = SBRD_it\n\n# Final time report\nTotal_time = time() - T_0\nprint(Total_time)\n\n1235.6397669315338\n\n\n\nplot_single_algorithm(alg_name=\"SBRD\", varName=\"S2_isNash\", title=\"\", mean_name=\"isNash\", ylabel=\"Prob. conver. to NE\", axis=1, binomial=True, legend_loc=\"upper left\")\n\n\n\n\n\n\n\n\n\nplot_single_algorithm(alg_name=\"SBRD\", varName=\"S2_nrSteps\", mean_name=\"nrSteps\", title=\"\", ylabel=\"Steps\", axis=1, isPositive=True, log=False, legend_loc=\"upper right\")"
  },
  {
    "objectID": "Learning/Python/Papers/SBRD.html#section-3.-finding-comparison-of-sbrd-and-spgd-in-3-player-random-potential-games",
    "href": "Learning/Python/Papers/SBRD.html#section-3.-finding-comparison-of-sbrd-and-spgd-in-3-player-random-potential-games",
    "title": "Utility functions (please skip to the next section)",
    "section": "Section 3. Finding: comparison of SBRD and SPGD in 3-player random potential games",
    "text": "Section 3. Finding: comparison of SBRD and SPGD in 3-player random potential games\n\n# Experimental setup\nsamples = 1000\nlambda_vals = [0.85+0.09999999999*0.25*i for i in range(7)] # List of lambda values to test\nA_vals = [50]\n\n# Outputs to Track\n## Policy Gradient Dynamics\nPGD_S3_isNash = np.full((len(lambda_vals), len(A_vals), samples), False, dtype=bool) # {0,1} veridicity of Nash in Policy Gradient Dynamics\nPGD_S3_numIte = np.zeros((len(lambda_vals), len(A_vals), samples)) # Number of iterations in Policy Gradient Dynamics\nPGD_S3_valFin = np.zeros((len(lambda_vals), len(A_vals), samples)) # Final payoff for player 0 in Policy Gradient Dynamics\nPGD_S3_valAvg = np.zeros((len(lambda_vals), len(A_vals), samples)) # Average payoff for player 0 in Policy Gradient Dynamics\nPGD_S3_time = np.zeros((len(lambda_vals), len(A_vals), samples))   # Runtime in Policy Gradient Dynamics\n\n## Best Response Dynamics\nSBRD_S3_isNash = np.full((len(lambda_vals), len(A_vals), samples), False, dtype=bool) # {0,1} veridicity of Nash in Best Response Dynamics\nSBRD_S3_numIte = np.zeros((len(lambda_vals), len(A_vals), samples)) # Number of iterations in Best Response Dynamics\nSBRD_S3_val = np.zeros((len(lambda_vals), len(A_vals), samples)) # Final payoff for player 0 in Best Response Dynamics\nSBRD_S3_time = np.zeros((len(lambda_vals), len(A_vals), samples))   # Runtime in Best Response Dynamics\n\n\nmax_A = A_vals[-1]  # Maximum number of actions (fixed at 50)\nnp.random.seed(2025) #We set the random seed for reproducibility \n\nT_0 = time()  # Start the global timer\n\nfor count_lam, lam in enumerate(lambda_vals):  # Loop over correlation values\n    for i in range(samples):  # Loop over sample repetitions\n        # Generate a shared reward matrix for both algorithms\n        G = generate_reward_matrix(3, max_A, lam)\n\n        for count_A, A in enumerate(A_vals):  # Loop over population sizes (fixed here)\n            t_0 = time()  # Start timer for PGD\n            PGD_it, PGD_avg_val, PGD_val = gradient_ascent_dynamics(G, A)\n            t = time() - t_0  # Elapsed time\n\n            PGD_S3_isNash[count_lam, count_A, i] = (PGD_it &lt; 50_000 - 1)  # Converged?\n            PGD_S3_numIte[count_lam, count_A, i] = PGD_it\n            PGD_S3_valFin[count_lam, count_A, i] = PGD_val\n            PGD_S3_valAvg[count_lam, count_A, i] = PGD_avg_val\n            PGD_S3_time[count_lam, count_A, i] = t\n\n            # === Best Response Dynamics (SBRD) ===\n            t_0 = time()  # Start timer for SBRD\n            SBRD_len, SBRD_it, SBRD_val_curr = best_response_dynamics(G, A)\n            t = time() - t_0  # Elapsed time\n\n            # Store SBRD results\n            SBRD_S3_isNash[count_lam, count_A, i] = (SBRD_len == 1)  # Converged to pure NE?\n            SBRD_S3_numIte[count_lam, count_A, i] = SBRD_it\n            SBRD_S3_val[count_lam, count_A, i] = SBRD_val_curr\n            SBRD_S3_time[count_lam, count_A, i] = t\n\n# === Time Summary ===\nTot_time = time() - T_0\nTot_time_SBRD = np.sum(SBRD_S3_time)\nTot_time_PGD = np.sum(PGD_S3_time)\nTot_time_gener = Tot_time - Tot_time_SBRD - Tot_time_PGD\n\n# Print runtime breakdown\nprint(f\"Total time to run: {round(Tot_time, 1)} s\")\nprint(f\"Percentage of the time spent on random generation of matrix: {round((Tot_time_gener / Tot_time) * 100, 1)}%\")\nprint(f\"Percentage of the time spent on SBRD algorithm: {round((Tot_time_SBRD / Tot_time) * 100, 1)}%\")\nprint(f\"Percentage of the time spent on PGD algorithm: {round((Tot_time_PGD / Tot_time) * 100, 1)}%\")\n\nTotal time to run: 4802.2 s\nPercentage of the time spent on random generation of matrix: 0.7%\nPercentage of the time spent on SBRD algorithm: 0.1%\nPercentage of the time spent on PGD algorithm: 99.2%\n\n\n\ncompare_algorithms(PGD_varName=\"S3_time\", SBRD_varName=\"S3_time\", title=\"\", mean_1_name=\"SPGD±2SE\", mean_2_name=\"SBRD±2SE\", yLabel=\"Seconds\", axis=1, variance=True, isPositive=True, log=True, legend_loc=\"upper right\")\n\n/var/folders/v1/4466w3pn1216dm8152kjp_3r0000gn/T/ipykernel_18423/3723386220.py:260: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n  ax.fill_between(x_vals, y_lower, y_upper, color=color, alpha=0.2)#, label=f\"{label_ci}\")\n/var/folders/v1/4466w3pn1216dm8152kjp_3r0000gn/T/ipykernel_18423/3723386220.py:273: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n  plt.tight_layout(rect=[0, 0, 1, 0.96])\n\n\n\n\n\n\n\n\n\n\ncompare_algorithms(PGD_varName=\"S3_valFin\", SBRD_varName=\"S3_val\", title=\"\", mean_1_name=\"SPGD±2SE\", mean_2_name=\"SBRD±2SE\", yLabel=\"Value\", axis=1, variance=True, isPositive=True, only_if_conv=True, legend_loc=\"upper left\")\n\n\n\n\n\n\n\n\n\ncompare_algorithms(PGD_varName=\"S3_numIte\", SBRD_varName=\"S3_numIte\", title=\"\", mean_1_name=\"SPGD±2SE\", mean_2_name=\"SBRD±2SE\", yLabel=\"SSteps\", axis=1, variance=True, isPositive=True, log=True, legend_loc=\"upper right\")\n\n\n\n\n\n\n\n\n\ncompare_algorithms(PGD_varName=\"S3_valAvg\", SBRD_varName=\"S3_val\", title=\"\", mean_1_name=\"SPGD±2SE\", mean_2_name=\"SBRD±2SE\", yLabel=\"Value\", axis=1, variance=True, isPositive=True, legend_loc=\"upper right\")"
  },
  {
    "objectID": "Learning/Python/Papers/SBRD.html#section-a.-results-of-section-1.-also-hold-for-more-actions",
    "href": "Learning/Python/Papers/SBRD.html#section-a.-results-of-section-1.-also-hold-for-more-actions",
    "title": "Utility functions (please skip to the next section)",
    "section": "Section A. Results of Section 1. also hold for more actions",
    "text": "Section A. Results of Section 1. also hold for more actions\n\n# Number of simulations per (λ, N) setting\nsamples = 1_000\nlambda_vals = [0.09999999999*0.5*i for i in range(21)]\nA_vals = [500]\n\nSBRD_S4_twoCycles = np.full((len(lambda_vals), 1, samples), False, dtype=bool)\nSBRD_S4_nrSteps = np.zeros((len(lambda_vals), len(A_vals), samples))\n\n\nnp.random.seed(2025) #We set the random seed for reproducibility \nT_0 = time()  # Start timer for entire experiment\nmax_A = max(A_vals)\nfor count_lam, lam in enumerate(lambda_vals):  # Loop over each lambda value\n    for i in range(samples):  # Repeat experiment for statistical robustness\n        G = generate_reward_matrix(2, max_A, lam)  # Generate a payoff matrix with max_n actions and correlation lambda\n    \n        for count_A, A in enumerate(A_vals):  # Now restrict to smaller N if needed\n            # Run Best Response Dynamics and time it\n            SBRD_len, SBRD_it, SBRD_val_curr = best_response_dynamics(G, A)\n            SBRD_S4_twoCycles[count_lam, count_A, i] = (SBRD_len == 2)\n            SBRD_S4_nrSteps[count_lam, count_A, i] = SBRD_it\n\n# Final time report\nTotal_time = time() - T_0\nprint(Total_time)\n\n127.52515482902527\n\n\n\nplot_single_algorithm(alg_name=\"SBRD\", varName=\"S4_twoCycles\", title=\"\", mean_name=\"twoCycle\", ylabel=\"Prob. conver. to two-cycle\", axis=1, binomial=True, legend_loc=\"upper left\")\n\n\n\n\n\n\n\n\n\nplot_single_algorithm(alg_name=\"SBRD\", varName=\"S4_nrSteps\", mean_name=\"nrSteps\", title=\"\", ylabel=\"Steps\", axis=1, isPositive=True, log=False, legend_loc=\"upper right\")\n\n\n\n\n\n\n\n\n\nprint(round(lambda_vals[int(np.argmax(np.mean(SBRD_S4_twoCycles, axis=-1)&gt;0.5))],2))\nprint(round(lambda_vals[int(np.argmax(np.mean(SBRD_S4_twoCycles, axis=-1)&gt;0.9))],2))\n\n0.5\n0.75"
  },
  {
    "objectID": "Learning/Python/Papers/SBRD.html#section-b.1.-results-of-section-2.-also-hold-for-more-actions",
    "href": "Learning/Python/Papers/SBRD.html#section-b.1.-results-of-section-2.-also-hold-for-more-actions",
    "title": "Utility functions (please skip to the next section)",
    "section": "Section B.1. Results of Section 2. also hold for more actions",
    "text": "Section B.1. Results of Section 2. also hold for more actions\n\n# Number of simulations per (λ, N) setting\nsamples = 1000\nlambda_vals = [0.09999999999*0.5*i for i in range(21)]\nA_vals = [100]\n\nSBRD_S5_isNash = np.full((len(lambda_vals), 1, samples), False, dtype=bool)\nSBRD_S5_nrSteps = np.zeros((len(lambda_vals), len(A_vals), samples))\n\n\nnp.random.seed(2025) #We set the random seed for reproducibility \nT_0 = time()  # Start timer for entire experiment\nmax_A = max(A_vals)\nfor count_lam, lam in enumerate(lambda_vals):  # Loop over each lambda value\n    for i in range(samples):  # Repeat experiment for statistical robustness\n        G = generate_reward_matrix(3, max_A, lam)  # Generate a payoff matrix with max_n actions and correlation lambda\n    \n        for count_A, A in enumerate(A_vals):  # Now restrict to smaller N if needed\n            # Run Best Response Dynamics and time it\n            SBRD_len, SBRD_it, SBRD_val_curr = best_response_dynamics(G, A)\n            SBRD_S5_isNash[count_lam, count_A, i] = (SBRD_len == 1)\n            SBRD_S5_nrSteps[count_lam, count_A, i] = SBRD_it\n\n# Final time report\nTotal_time = time() - T_0\nprint(Total_time)\n\n860.9745609760284\n\n\n\nplot_single_algorithm(alg_name=\"SBRD\", varName=\"S5_isNash\", title=\"\", mean_name=\"isNash\", ylabel=\"Prob. conver. to NE\", axis=1, binomial=True, legend_loc=\"upper left\")\n\n\n\n\n\n\n\n\n\nplot_single_algorithm(alg_name=\"SBRD\", varName=\"S5_nrSteps\", mean_name=\"nrSteps\", title=\"\", ylabel=\"Steps\", axis=1, isPositive=True, log=False, legend_loc=\"upper right\")"
  },
  {
    "objectID": "Learning/Python/Papers/SBRD.html#section-b.2.-results-of-section-2.-also-hold-for-more-players",
    "href": "Learning/Python/Papers/SBRD.html#section-b.2.-results-of-section-2.-also-hold-for-more-players",
    "title": "Utility functions (please skip to the next section)",
    "section": "Section B.2. Results of Section 2. also hold for more players",
    "text": "Section B.2. Results of Section 2. also hold for more players\n\n# Number of simulations per (λ, N) setting\nsamples = 1_000\nlambda_vals = [0.09999999999*0.5*i for i in range(21)]\nA_vals = [50]\n\nSBRD_S6_isNash = np.full((len(lambda_vals), 1, samples), False, dtype=bool)\nSBRD_S6_nrSteps = np.zeros((len(lambda_vals), len(A_vals), samples))\n\n\nnp.random.seed(2025) #We set the random seed for reproducibility \nT_0 = time()  # Start timer for entire experiment\nmax_A = max(A_vals)\nfor count_lam, lam in enumerate(lambda_vals):  # Loop over each lambda value\n    for i in range(samples):  # Repeat experiment for statistical robustness\n        G = generate_reward_matrix(4, max_A, lam)  # Generate a payoff matrix with max_n actions and correlation lambda\n    \n        for count_A, A in enumerate(A_vals):  # Now restrict to smaller N if needed\n            # Run Best Response Dynamics and time it\n            SBRD_len, SBRD_it, SBRD_val_curr = best_response_dynamics(G, A)\n            SBRD_S6_isNash[count_lam, count_A, i] = (SBRD_len == 1)\n            SBRD_S6_nrSteps[count_lam, count_A, i] = SBRD_it\n\n# Final time report\nTotal_time = time() - T_0\nprint(Total_time)\n\n8539.04519701004\n\n\n\nplot_single_algorithm(alg_name=\"SBRD\", varName=\"S6_isNash\", title=\"\", mean_name=\"isNash\", ylabel=\"Prob. conver. to NE\", axis=1, binomial=True, legend_loc=\"upper left\")\n\n\n\n\n\n\n\n\n\nplot_single_algorithm(alg_name=\"SBRD\", varName=\"S6_nrSteps\", mean_name=\"nrSteps\", title=\"\", ylabel=\"Steps\", axis=1, isPositive=True, log=False, legend_loc=\"upper right\")"
  },
  {
    "objectID": "Learning/Python/Papers/SBRD.html#section-c.1.-results-of-section-3.-also-hold-for-more-actions",
    "href": "Learning/Python/Papers/SBRD.html#section-c.1.-results-of-section-3.-also-hold-for-more-actions",
    "title": "Utility functions (please skip to the next section)",
    "section": "Section C.1. Results of Section 3. also hold for more actions",
    "text": "Section C.1. Results of Section 3. also hold for more actions\n\n# Experimental setup\nsamples = 1000\nlambda_vals = [0.85+0.09999999999*0.25*i for i in range(7)] # List of lambda values to test\nA_vals = [100]\n\n# Outputs to Track\n## Policy Gradient Dynamics\nPGD_S7_isNash = np.full((len(lambda_vals), len(A_vals), samples), False, dtype=bool) # {0,1} veridicity of Nash in Policy Gradient Dynamics\nPGD_S7_numIte = np.zeros((len(lambda_vals), len(A_vals), samples)) # Number of iterations in Policy Gradient Dynamics\nPGD_S7_valFin = np.zeros((len(lambda_vals), len(A_vals), samples)) # Final payoff for player 0 in Policy Gradient Dynamics\nPGD_S7_valAvg = np.zeros((len(lambda_vals), len(A_vals), samples)) # Average payoff for player 0 in Policy Gradient Dynamics\nPGD_S7_time = np.zeros((len(lambda_vals), len(A_vals), samples))   # Runtime in Policy Gradient Dynamics\n\n## Best Response Dynamics\nSBRD_S7_isNash = np.full((len(lambda_vals), len(A_vals), samples), False, dtype=bool) # {0,1} veridicity of Nash in Best Response Dynamics\nSBRD_S7_numIte = np.zeros((len(lambda_vals), len(A_vals), samples)) # Number of iterations in Best Response Dynamics\nSBRD_S7_val = np.zeros((len(lambda_vals), len(A_vals), samples)) # Final payoff for player 0 in Best Response Dynamics\nSBRD_S7_time = np.zeros((len(lambda_vals), len(A_vals), samples))   # Runtime in Best Response Dynamics\n\n\nmax_A = A_vals[-1]  # Maximum number of actions (fixed at 50)\nnp.random.seed(2025) #We set the random seed for reproducibility \n\nT_0 = time()  # Start the global timer\n\nfor count_lam, lam in enumerate(lambda_vals):  # Loop over correlation values\n    for i in range(samples):  # Loop over sample repetitions\n        # Generate a shared reward matrix for both algorithms\n        G = generate_reward_matrix(3, max_A, lam)\n\n        for count_A, A in enumerate(A_vals):  # Loop over population sizes (fixed here)\n            t_0 = time()  # Start timer for PGD\n            PGD_it, PGD_avg_val, PGD_val = gradient_ascent_dynamics(G, A)\n            t = time() - t_0  # Elapsed time\n\n            PGD_S7_isNash[count_lam, count_A, i] = (PGD_it &lt; 50_000 - 1)  # Converged?\n            PGD_S7_numIte[count_lam, count_A, i] = PGD_it\n            PGD_S7_valFin[count_lam, count_A, i] = PGD_val\n            PGD_S7_valAvg[count_lam, count_A, i] = PGD_avg_val\n            PGD_S7_time[count_lam, count_A, i] = t\n\n            # === Best Response Dynamics (SBRD) ===\n            t_0 = time()  # Start timer for SBRD\n            SBRD_len, SBRD_it, SBRD_val_curr = best_response_dynamics(G, A)\n            t = time() - t_0  # Elapsed time\n\n            # Store SBRD results\n            SBRD_S7_isNash[count_lam, count_A, i] = (SBRD_len == 1)  # Converged to pure NE?\n            SBRD_S7_numIte[count_lam, count_A, i] = SBRD_it\n            SBRD_S7_val[count_lam, count_A, i] = SBRD_val_curr\n            SBRD_S7_time[count_lam, count_A, i] = t\n\n# === Time Summary ===\nTot_time = time() - T_0\nTot_time_SBRD = np.sum(SBRD_S7_time)\nTot_time_PGD = np.sum(PGD_S7_time)\nTot_time_gener = Tot_time - Tot_time_SBRD - Tot_time_PGD\n\n# Print runtime breakdown\nprint(f\"Total time to run: {round(Tot_time, 1)} s\")\nprint(f\"Percentage of the time spent on random generation of matrix: {round((Tot_time_gener / Tot_time) * 100, 1)}%\")\nprint(f\"Percentage of the time spent on SBRD algorithm: {round((Tot_time_SBRD / Tot_time) * 100, 1)}%\")\nprint(f\"Percentage of the time spent on PGD algorithm: {round((Tot_time_PGD / Tot_time) * 100, 1)}%\")\n\nTotal time to run: 35111.9 s\nPercentage of the time spent on random generation of matrix: 0.7%\nPercentage of the time spent on SBRD algorithm: 0.0%\nPercentage of the time spent on PGD algorithm: 99.3%\n\n\n\ncompare_algorithms(PGD_varName=\"S7_time\", SBRD_varName=\"S7_time\", title=\"\", mean_1_name=\"SPGD±2SE\", mean_2_name=\"SBRD±2SE\", yLabel=\"Seconds\", axis=1, variance=True, isPositive=True, log=True, legend_loc=\"upper right\")\n\n\n\n\n\n\n\n\n\ncompare_algorithms(PGD_varName=\"S7_valFin\", SBRD_varName=\"S7_val\", title=\"\", mean_1_name=\"SPGD±2SE\", mean_2_name=\"SBRD±2SE\", yLabel=\"Value\", axis=1, variance=True, isPositive=True, only_if_conv=True, legend_loc=\"upper left\")\n\n\n\n\n\n\n\n\n\ncompare_algorithms(PGD_varName=\"S7_numIte\", SBRD_varName=\"S7_numIte\", title=\"\", mean_1_name=\"SPGD±2SE\", mean_2_name=\"SBRD±2SE\", yLabel=\"Steps\", axis=1, variance=True, isPositive=True, log=True, legend_loc=\"upper right\")\n\n\n\n\n\n\n\n\n\ncompare_algorithms(PGD_varName=\"S7_valAvg\", SBRD_varName=\"S7_val\", title=\"\", mean_1_name=\"SPGD±2SE\", mean_2_name=\"SBRD±2SE\", yLabel=\"Value\", axis=1, variance=True, isPositive=True, legend_loc=\"upper right\")"
  },
  {
    "objectID": "main_pages/miscellanea.html",
    "href": "main_pages/miscellanea.html",
    "title": "Miscellanea",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\nAmongst the things I like: Books, Movies, Cooking.\n\nBoooksMovies\n\n\n\nBooks\n\nI like reading books. This is a great website to find your next read (I also like my own analysis of this list). I have used a lot the platform Audible.\n\nRead in 2025Read in 2024Read in 2023\n\n\n\n\n\n\n\n\n\n\n\nTitle\nAuthor\nStatus\nCompl. on\n\n\n\n\nLincoln in the Bardo\nGeorge Saunders\n\nMay ’25\n\n\nStaring at the Sun\nIrvin D. Yalom\n\nMay ’25\n\n\nIt Lasts Forever and Then It’s Over\nAnne de Marcken\n\nMay ’25\n\n\nCharlotte’s Web\nElwyn B. White\n\nMay ’25\n\n\nPerfection\nVincenzo Latronico\n\nMay ’25\n\n\nThis Is How You Lose the Time War\nAmal El-Mohtar and Max Gladstone\n\nApr ’25\n\n\nCirce\nMadeline Miller\n\nApr ’25\n\n\nProphet Song\nPaul Lynch\n\nApr ’25\n\n\nThe Golden Enclaves\nNaomi Novik\n\nApr ’25\n\n\nThe Last Graduate\nNaomi Novik\n\nApr ’25\n\n\nA Deadly Education\nNaomi Novik\n\nApr ’25\n\n\nFoundation\nIsaac Asimov\n\nMar ’25\n\n\nA Wizard of Earthsea\nUrsula K. Le Guin\n\nMar ’25\n\n\nIl Barone Rampante\nItalo Calvino\n\nMar ’25\n\n\nBrave New World\nAldous Huxley\n\nMar ’25\n\n\nKlara and the Sun\nKazuo Ishiguro\n\nMar ’25\n\n\nWolf Hall\nHilary Mantel\n\nFeb ’25\n\n\nDune\nFrank Herbert\n\nFeb ’25\n\n\nO Natal de Poirot\nAgatha Christie\n\nJan ’25\n\n\nA noite das bruxas\nAgatha Christie\n\nJan ’25\n\n\n\n\n\nI interrupted my readings between Feb and Dec 2024 to improve my Spanish (was A2-B1, currently C1), and my Portuguese (currently B1). I am planning to write a page on how I learn languages, as it’s something I’m passionate about and have some experience doing.\n\n\n\n\n\n\n\n\n\nTitle\nAuthor\nStatus\nCompl. on\n\n\n\n\nFlights\nOlga Tokarczuk\n\n\n\n\nI Know Why the Caged Bird Sings\nMaya Angelou\n\n\n\n\nNotes from Underground\nFyodor Dostoevsky\n\n\n\n\nThe Call of the Wild\nJack London\n\nFeb ’24\n\n\nAlice’s Adventures in Wonderland\nLewis Carroll\n\nJan ’24\n\n\nThe Metamorphosis\nFranz Kafka\n\nJan ’24\n\n\nBartleby, the Scrivaner\nHerman Melville\n\nJan ’24\n\n\nWhite Nights\nFyodor Dostoevsky\n\nJan ’24\n\n\nThe Idiot\nFyodor Dostoevsky\n\nJan ’24\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nAuthor\nStatus\nCompl. on\n\n\n\n\nIl fu Mattia Pascal\nLuigi Pirandello\n\nDec ’23\n\n\nFirst Love\nIvan Turgenev\n\nDec ’23\n\n\nThe Kreutzer Sonata\nLeo Tolstoy\n\nDec ’23\n\n\nThe Strange Case of Dr. Jekyll and Mr. Hyde\nRobert L. Stevenson\n\nDec ’23\n\n\nThe Death of Ivan Ilyich\nLeo Tolstoy\n\nDec ’23\n\n\nMurtagh\nCristopher Paolini\n\nNov ’23\n\n\nEmma\nJane Austen\n\nNov ’23\n\n\nPride and Prejudice\nJane Austen\n\nNov ’23\n\n\nPersuasion\nJane Austen\n\nOct ’23\n\n\nUno, nessuno e centomila\nLuigi Pirandello\n\nOct ’23\n\n\nMacbeth\nWilliam Shakespeare\n\nOct ’23\n\n\nSphere\nMichael Crichton\n\nSep ’23\n\n\nThe Buried Giant\nKazuo Ishiguro\n\nSep ’23\n\n\nLa Storia\nElsa Morante\n\nSep ’23\n\n\nOedipus at Colonus\nSophocles\n\nAug ’23\n\n\nBaol\nStefano Benni\n\nAug ’23\n\n\nOedipus Rex\nSophocles\n\nAug ’23\n\n\nPantera\nStefano Benni\n\nAug ’23\n\n\nBlues in Sedici\nStefano Benni\n\nAug ’23\n\n\nThe Pastures of Heaven\nJohn Steinbeck\n\nAug ’23\n\n\nThe Remains of the Day\nKazuo Ishiguro\n\nJul ’23\n\n\nThe Return of the King\nJ.R.R. Tolkien\n\nJul ’23\n\n\nSwimming in the Dark\nTomasz Jedrowski\n\nJul ’23\n\n\nThe Two Towers\nJ.R.R. Tolkien\n\nJun ’23\n\n\nThe Fellowship of the Ring\nJ.R.R. Tolkien\n\nJun ’23\n\n\nIl Bar sotto il Mare\nStefano Benni\n\nMay ’23\n\n\n2001: A Space Odyssey\nArthur C. Clarke\n\nMay ’23\n\n\nNever let Me go\nKazuo Ishiguro\n\nMay ’23\n\n\nNocturnes\nKazuo Ishiguro\n\nMay ’23\n\n\nThe Time Machine\nH.G. Wells\n\nMay ’23\n\n\nA little Life\nHanya Yanagihara\n\nMay ’23\n\n\nA Room with a View\nE.M. Forster\n\nApr ’23\n\n\nDrive your Plow over the Bones of the Dead\nOlga Tokarczuk\n\nMar ’23\n\n\n\n\n\n\n\nNext up (Suggestions appreciated) \n\n\n\n\n\n\n\n\nTitle\nAuthor\n\n\n\n\nDemon Copperhead\nBarbara Kingsolver\n\n\nA Fine Balance\nRohinton Mistry\n\n\nThe Bell Jar\nSylvia Plath\n\n\nThe Once and Future King\nT. H. White\n\n\nThe Found and the Lost\nUrsula K. Le Guin\n\n\nIl sistema periodico\nPrimo Levi\n\n\nCanne al vento\nGrazia Deledda\n\n\nBeloved\nToni Morrison\n\n\nSong of Solomon\nToni Morrison\n\n\nLa luna e i falò\nCesare Pavese\n\n\nOrlando\nVirginia Woolf\n\n\nHeart of Darkness\nJoseph Conrad\n\n\nAdventures of Huckleberry Finn\nMark Twain\n\n\nLolita\nVladimir Nabokov\n\n\nI Am a Cat\nSoseki Natsume\n\n\nThree Men in a Boat\nJerome K. Jerome\n\n\n\n\n\n\nMovies\n\nI love watching movies. I am a proud owner of an Odeon membership, (which I stronly suggest to any UK-resident movie lover). I am also happy to pass along a list of good movies which was indicated to me from a dear cinephilic friend.\nIf you want to follow my film-watching, you can add me on Letterboxd (it’s like a Facebook for movies, super nice website).",
    "crumbs": [
      "Miscellanea"
    ]
  },
  {
    "objectID": "main_pages/research.html",
    "href": "main_pages/research.html",
    "title": "Research",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics",
    "crumbs": [
      "Research"
    ]
  },
  {
    "objectID": "main_pages/research.html#future-projects",
    "href": "main_pages/research.html#future-projects",
    "title": "Research",
    "section": "Future Projects",
    "text": "Future Projects\nI welcome collaboration with anyone who would like to work with me on one (or more) of the following. These are only the projects for which I HAVE a clear research path in mind, with specific implementations, experiments, and analysis to do, I just didn’t have the time to implement them yet. Please get in touch with me even just to chat about them, or if you’re interested in collaborating.\n\nCan RL learn Combinatorial Games? Reinforcement Learning (RL) is really good at games, but is possibly really bad at Graph Theory (although initial results were quite optimistic [1, 2]). Would RL be good at Combinatorial Games? I am particularly interested to explore this about games on graphs. In particular the Balance Game or some Maker Breaker games.\nWhat can RL do in Graph Theory? There are some results that seem to indicate that RL is not good at Graph Theoretical problems [3, 4]. However, RL is clearly good at solving certain Graph-theoretical problems, and initial results were quite optimistic [1, 2]. What is the reason behind this variying behaviour?\nSparsity? Quantization? What about both? Two well-known memory-reduction methods in Neural Networks are Sparsity and Quantization. These two methods are not orthogonal. However I do believe that there is a way of improving the current SotA to produce a lighter version of NN using the interplay between the two. The literature in the area seems to go towards a natural direction that hasn’t been developed, in my opinion, to the fullest.\nLet’s make EU healthier This is a project that has a wider breath and is not only linked to research. If you’re passionate about nutrition, hardcore computer science, and want to make a tangible impact, do get in touch.",
    "crumbs": [
      "Research"
    ]
  },
  {
    "objectID": "main_pages/research.html#past-and-present-projects",
    "href": "main_pages/research.html#past-and-present-projects",
    "title": "Research",
    "section": "Past and Present Projects",
    "text": "Past and Present Projects\n\nPapersTalks (Selected)Theses and ProjectsTripsOther\n\n\nWork in progress\n\nMethodology for carbon credit assessment with A. Perrella, G. Marastoni (2025++)\nPartition universality for hypergraphs  with P. Allen, J. Böttcher (2025++)\nAn extension of the transference principlewith P. Allen, J. Böttcher, J. Lada (2025+)\nBest Response Dynamics for Random Games with G. Ashkenazi-Golan, E. Plumb, J. Skokan (2025++)\n\nSubmitted\n\nSimultaneous Best-Response Dynamics in Random Potential Games with G. Ashkenazi-Golan, E. Plumb Submit. to double-blind conferencePaper with code\nReinforcement Learning, Collusion, and the Folk Theorem. with G. Ashkenazi-Golan, E. Plumb Submit. Econometrica (2025)\nDirac’s theorem for graphs of bounded bandwidth. with A.E. Díaz, P. Gupta, O. Parczyk, A. Sgueglia Submit. Electron. J. Comb. (2024)\n\nAccepted - Graphs with large minimum degree and no short odd cycles are 3-colourable. with J. Böttcher, N. Frankl, O. Parczyk, J. SkokanAccept. Comb. Theory\nPublished\n\nOn product Schur triples in the integers. with L. Mattos, O. Parczyk SIAM Journal on Discrete Mathematics. Vol 39, Iss. 2 (2025)\nThe Ramsey numbers of squares of paths and cycleswith P. Allen, B. Roberts, J. Skokan  The Electronic Journal of Combinatorics. Vol 31, Iss. 2 (2024), P2.11\n\nNotes/Not for publication\n\nRe-ILS: a metaheuristic approach for cardinality-constrained optimization  with Jian Shen (internal Amazon publication)\nDensity of small diameter subgraphs in \\(K_r\\)-free graphs. with E.K. Hng\n\n\n\n\n\n\n\nTitle\nDate\nOccasion\nPlace\n\n\n\n\nProduct-free subsets of \\([n]\\)\nOct ’23\nLSE Seminar\nLondon\n\n\nPartition Universality\nAug ’23\nEurocomb\nPrague\n\n\nThe Ramsey numbers of \\(P_{3n}^2\\) and \\(C_{3n}^2\\)\nSep ’23\nDMV (Invited speaker)\nIlmenau\n\n\n\nApr ’23\nInvited seminar\nPrague\n\n\n\nJul ’22\nICGT\nMontpellier\n\n\n\nJul ’22\nInvited seminar\nTU Hamburg\n\n\nChromatic profile of \\(\\{C_3,\\dots{},C_{2k-1}\\}\\)\nMar ’23\nPCC\nBirmingham\n\n\n\nJul ’22\nRSA\nPoznan\n\n\n\nJul ’22\nICGT\nMontpellier\n\n\n\nJul ’22\nInvited seminar\nTU Hamburg\n\n\nAbout the Pentagon Conjecture\nNov ’20\nLSE Seminar\nLondon\n\n\nMinimal Ramsey Graphs for Ciclicity\nMay ’19\nETHZ Mittagsseminar\nZurich\n\n\nDimensione di Hausdorff del Moto Browniano\nMay ’19\nBSc Defense\nPisa\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat\nWhen\nWhere\nWhy\n\n\n\n\nGraph-theoretical Tools in Statistics\n2022\nLSE\nMini-internship\n\n\nA discussion about the Pentagon Problem\n2020\nETHZ\nMSc Thesis\n\n\nSeparator Theorems\n2019\nETHZ\nSemester Paper\n\n\nA Glimpse of Young’s Tableaux\n2019\nETHZ\nReading Course\n\n\nOn the Hausdorff Dimension of Brownian Motion\n2018\nPisa Univ.\nBSc Thesis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat\nWhen\nWhere\nInstit.\nType\nFunded\n\n\n\n\nDMV\nOct ’23\nIlmenau\n\nConference (invited)\nLSE\n\n\nCPMC\nSept ’23\nZagreb\n\nWorkshop\nLSE\n\n\nEurocomb\nAug ’23\nPrague\n\nConference\nLSE\n\n\nEEML\nJul ’23\nKošice\n\nSummer School\nLSE\n\n\nALGA\nJun ’23\nRagusa\n\nConference\nCIVICA Grant\n\n\nUCLW\nMay ’23\nLondon\nUCL\nWorkshop\n\n\n\nPSSC\nApr ’23\nPrague\nCharles Uni.\nSummer School\nCharles Uni.\n\n\nPCC\nMar ’23\nBirmingham\n\nConference\nLSE\n\n\nResearch Visit\nAug ’22\nBerlin\nFU Berlin\nVisit\nLMS Grant\n\n\nRSA\nAug ’22\nGniezno\n\nConference\nLSE\n\n\nResearch visit\nJul ’22\nPrague\nCzech Academy of Science\nVisit\nCzech Academy of Science\n\n\nPSSDM\nJul ’22\nPrague\nCharles Uni.\nSummer School\nSummer School\n\n\nICGT\nJul ’22\nMontpellier\n\nConference\nLSE\n\n\nResearch visit\nMay ’22\nHamburg\nTU Hamburg\nVisit\nTU Hamburg\n\n\n\n\n\n\nOrganiser\n\nPCC (Main organiser), Apr 2023, University of London and BCC. (National conference for postgraduate students).\nLSE PhD CGO Seminar (Main Organiser), 2022/23.\n\nGrants and invitations\n\nDMV Invited Speaker. Ilmenau. 2023.\nLMS Computer Science Small Grant (700£). London Mathematical Society. Funded visit to Berlin. 2022.\nLSE Contribution Award. Dept of Mathematics. LSE. 2021.",
    "crumbs": [
      "Research"
    ]
  },
  {
    "objectID": "main_pages/curriculum.html",
    "href": "main_pages/curriculum.html",
    "title": "Curriculum",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\nRelevant documents:\n\nCourse content of many courses I followed and all courses I taught.\nTranscript of Records of BSc and MSc.\nNormal CV.\n\n\n\n\n\n\n\n---\ndisplayMode: compact\n---\ngantt\n    title Curriculum - Overview\n    dateFormat DD-MM-YYYY\n    axisFormat   %b %Y\n    section BSc\n    Pisa Univ - GPA 110/110: L1, 01-09-2015, 1048d\n    section MSc\n    ETHZ - GPA 5.8/6: L1, 01-09-2018, 700d\n    section PhD\n    London School of Economics: L1, 01-09-2020, 1369d\n    LSE : L2, 01-01-2025, 180d\n    section Intern\n    AMZN : L1, 01-06-2024, 214d\n\n\n\n\n\n\n\n\n\n\n\njourney\n    title Technical Skills\n      Maths: 9: Research, Taught\n      ML, RL and Stats: 8: Taught, Research\n      Python: 7: Hobby, Taught\n      Finance: 4: Taught",
    "crumbs": [
      "Curriculum Vitae"
    ]
  },
  {
    "objectID": "Learning/Old_Work/OldWork.html",
    "href": "Learning/Old_Work/OldWork.html",
    "title": "University Notes",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\nYou can find here some notes I took throught my years of education. Unfortunately, some of this material is in Italian. However, I hope it might be helpful to some students.\n\nGeometria Analitica e Algebra Lineare: Parte 1, Parte 2, Parte 3. Appunti completi di ottimo corso annuale tenuto dalla Prof. Fortuna presso l’università di Pisa nell’anno accademico 2015/16.\nAlgebra I: Automorfismi di \\(S_n\\), Prodotto libero di Gruppi, Esercitazioni 1, Esercitazioni Teoria di Galois. Appunti parziali di lezioni ed esercitazioni di un corso tenuto nell’anno accademico 2016/17 dai professori Gaiffi e Callegaro.",
    "crumbs": [
      "Learning",
      "Old Notes",
      "Old Work"
    ]
  },
  {
    "objectID": "Learning/Python/CF/Easy/1758A.html",
    "href": "Learning/Python/CF/Easy/1758A.html",
    "title": "1758A",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n Click the title to see the text of the problem on Codeforces",
    "crumbs": [
      "Learning",
      "Python",
      "Codeforces",
      "Easy",
      "1758A"
    ]
  },
  {
    "objectID": "Learning/Python/Useful/Arxiv.html",
    "href": "Learning/Python/Useful/Arxiv.html",
    "title": "Everyday email",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\nEvery morning, I receive an email from Arxiv. Arxiv is an online platform used in the scientific community to share new results, quite similar to a Facebook, LinkedIn or Instagram for nerds scientists. These emails are super cool: they contain all the results published on the platform about your area(s) of interest in the last 24hrs, and a link to the relevant papers. This is quite useful and it allows you to keep track of the recent results without too much effort.\nHowever, there is a (small) problem: every new article has a page and a pdf. The page only contains the abstract, the pdf contains the whole article. Here’s the pickle: in the email is only contained the link to the page of the article, and not to the pdf.\nSo every morning I have to click the link to the papers I’m interested in, and THEN click again in the page to find the pdf. TWO CLICKS TO READ AN ARTICLE? That’s too much. From today, no more!\n\ndef get_pdf_url(line: \"line of email with url\") -&gt; \"url of the pdf\":\n    ### We assume a lot about the structure of the line of the link.\n    if \"/abs/\" not in line:\n        return \"https://www.google.com\"\n    sta = line.split(\"/abs/\")[1]\n    end = sta.find(\" , \")\n    return \"https://arxiv.org/pdf/\"+sta[:end]+\".pdf\"\n\nimport webbrowser\ntoday = open(\"./today.txt\",\"r\")\nfor line in today.readlines():\n    if \"https\" in line:\n        url = get_pdf_url(line)\n        webbrowser.open(url)\nTo use this code is enough to:\n\nSave the code above in a file with filename ending in .py,\nEvery morning, copy your email in a file with name “today.txt” in the same folder as the Python file,\nExecute the Python file.\n\nMake sure you have installed webbrowser with pip install webbrowser in the terminal.",
    "crumbs": [
      "Learning",
      "Python",
      "Useful",
      "Arxiv"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Homepage",
    "section": "",
    "text": "I am currently a PhD student in the department of Mathematics of LSE; my interests are mainly in Graph Theory, Game Theory, and Reinforcement Learning, but I’m always happy to explore new areas.\nAlongside my university projects, I currently am:\n\nCollaborating with the UGUALI! referendum, aiming to introduce equality between marriage and civil unions in Italy (de-facto introducing same-sex marriage in Italy).\nLeading a cross-field project for a EU proposal of new regulations regarding nutritional information on food packaging.\nContributing to a project for Carbon Credit Assessment, in collaboration with the Paraguayan government.\nWriting a cooking book with all my family’s traditional recipes.\n\n\n\n\n\n\n\n\n\n\n\n\nContact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\nFavourite quotes\n\n\n\n\n\nNew Quote\n\n\n\n\n\n\n\n\n\nSongs I like\n\n\n\n\n\nNew Song",
    "crumbs": [
      "Homepage"
    ]
  },
  {
    "objectID": "Teaching/ST310.html",
    "href": "Teaching/ST310.html",
    "title": "ST310 (Machine Learning)",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInternet is a great resource. Use it. Some resources I like:\n\nMIT OpenCourseWare,\nStanford,\nHarvard.\n\n\n\n\n\n\n\n\n\n\nBeware, the Crime!\n\n\n\nIt is illegal to download articles and books from pages like LibGen, Sci-hub or from Telegram bots like @scihubot. Also, DO NOT use VPN to protect your freedom of education (Opera offers a free VPN).\n\n🙃\n\n\n\n\n\n\nCourse content (Official)\n\nThe primary focus of this course is on the core machine learning techniques in the context of high-dimensional or large datasets (i.e. big data). The first part of the course covers elementary and important statistical methods including nearest neighbours, linear regression, logistic regression, regularisation, cross-validation, and variable selection. The second part of the course deals with more advanced machine learning methods including regression and classification trees, random forests, bagging, boosting, deep neural networks, k-means clustering and hierarchical clustering. The course will also introduce causal inference motivated by analogy between double machine learning and two-stage least squares. All the topics will be delivered using illustrative real data examples. Students will also gain hands-on experience using R or Python (programming languages and software environments for data analysis, computing and visualisation).\n\nMaterial and solutions\n\nI did not write the following material, which was prepared by Joshua Loftus. My role was simply to present the content of the seminars and the solutions in class.\n\n\n\nWeek\nSeminar Material\n\n\n\n\nWeek 1\nSeminar\n\n\nWeek 2\nSeminar\n\n\nWeek 3\nSeminar\n\n\nWeek 4\n\npart 1\npart 2\n\n\n\nWeek 5\n\npart 1\npart 2\n\n\n\nWeek 6\n\npart 1\npart 2\n\n\n\nWeek 7\n\npart 1\npart 2\n\n\n\nWeek 8\n\npart 1\npart 2\npart 3\npart 4\n\n\n\nWeek 9\nSeminar\n\n\nWeek 10\nSeminar"
  },
  {
    "objectID": "Teaching/Pre-sessionals/Maths2.html",
    "href": "Teaching/Pre-sessionals/Maths2.html",
    "title": "Pre-sessionals - Maths 2",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInternet is a great resource. Use it. Some resources I like:\n\nMIT OpenCourseWare,\nStanford,\nHarvard.\n\n\n\n\n\n\n\n\n\n\nBeware, the Crime!\n\n\n\nIt is illegal to download articles and books from pages like LibGen, Sci-hub or from Telegram bots like @scihubot. Also, DO NOT use VPN to protect your freedom of education (Opera offers a free VPN).\n\n🙃\n\n\n\n\n\n\nIntroduction to Derivatives\n\n\nIntroduction to Derivatives\n\nWhat is a Derivative?\n\nDefinition of a derivative as the instantaneous rate of change.\nNotation: \\(f'(x)\\), \\(\\frac{dy}{dx}\\).\nExample: Calculate the derivative of \\(f(x) = 3x^2 - 2x + 5\\).\nExercise: Find the derivative of given functions.\n\nThe Concept of Instantaneous Rate of Change\n\nUnderstanding how derivatives relate to slopes of tangent lines.\nExample: Interpret the derivative of a position function as velocity.\nExercise: Interpret derivatives in real-world contexts.\n\nNotation and Interpretation\n\nDiscuss the meaning of \\(f'(x)\\) and \\(\\frac{dy}{dx}\\) in context.\nEmphasize the connection between slope and rate of change.\nExercise: Match graphs of functions with their derivatives.\n\n\nDerivatives of Linear and Quadratic Functions\n\nFinding the Derivative of Linear Functions\n\nDeriving the derivative of linear functions.\nExample: Find the derivative of \\(L(x) = 2x + 4\\).\nExercise: Differentiate linear functions with different coefficients.\n\nFinding the Derivative of Quadratic Functions\n\nDifferentiating quadratic functions using the power rule.\nExample: Differentiate \\(q(x) = -3x^2 + 5x - 1\\).\nExercise: Derive quadratic functions with various coefficients.\n\nTangent Lines and Rates of Change\n\nConnecting derivatives to slopes of tangent lines.\nCalculating slopes of tangent lines at specific points.\nExample: Find the equation of the tangent line to \\(f(x) = x^2\\) at \\(x = 2\\).\n\n\nBasic Rules of Differentiation\n\nPower Rule for Differentiation\n\nStatement and derivation of the power rule.\nExample: Differentiate \\(g(x) = 4x^3 - 2x^2 + 7x\\) using the power rule.\nExercise: Apply the power rule to various functions.\n\nConstant Rule and Sum Rule\n\nUsing the constant rule and sum rule to differentiate functions.\nExample: Find the derivative of \\(h(x) = 3 + 2x^2 - 5x\\).\nExercise: Differentiate expressions involving constants and sums.\n\nDifferentiating Polynomial Functions\n\nApplying differentiation rules to polynomial functions.\nExample: Differentiate \\(p(x) = 6x^4 + 2x^3 - 9x^2 + 5\\).\nExercise: Differentiate given polynomial functions.\n\n\nApplications of Derivatives\n\nFinding Maxima and Minima\n\nUsing derivatives to locate critical points.\nIdentifying maxima, minima, and points of inflection.\nExample: Find the critical points of \\(g(x) = 2x^3 - 9x^2 + 12x\\).\n\nTangent Lines as Approximations\n\nUsing tangent lines for linear approximations.\nExample: Estimate \\(\\sqrt{9.2}\\) using the tangent line at \\(x = 9\\) for \\(f(x) = \\sqrt{x}\\).\n\nSimple Optimization Problems\n\nApplying derivatives to solve basic optimization problems.\nExample: Find the dimensions of a rectangle with maximum area given a fixed perimeter.\n\n\nConclusion and Recap\n\nSummarize the key concepts covered in the lecture.\n\nQ&A Session\nReferences (with exercises)"
  },
  {
    "objectID": "Teaching/Pre-sessionals/Maths4.html",
    "href": "Teaching/Pre-sessionals/Maths4.html",
    "title": "Pre-sessionals - Maths 4",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInternet is a great resource. Use it. Some resources I like:\n\nMIT OpenCourseWare,\nStanford,\nHarvard.\n\n\n\n\n\n\n\n\n\n\nBeware, the Crime!\n\n\n\nIt is illegal to download articles and books from pages like LibGen, Sci-hub or from Telegram bots like @scihubot. Also, DO NOT use VPN to protect your freedom of education (Opera offers a free VPN).\n\n🙃\n\n\n\n\n\n\nSupply and Demand Problems\n\n\nIntroduction to Supply and Demand\n\nBasic Concepts of Supply and Demand\n\nDefine supply and demand as fundamental economic concepts.\nExplain how they determine prices and quantities in markets.\nExample: Discuss the relationship between gas prices and demand during holidays.\n\nEquilibrium Point and Market Equilibrium\n\nDefine equilibrium point as the intersection of supply and demand curves.\nEmphasize the role of equilibrium in establishing market prices.\nExercise: Analyze a simple supply and demand graph to find equilibrium.\n\n\nSupply and Demand Equations\n\nModeling Supply and Demand using Linear Equations\n\nDiscuss how linear equations can represent supply and demand relationships.\nExample: Construct a linear demand equation based on given data.\nExercise: Write linear supply and demand equations from provided information.\n\nEquilibrium Price and Quantity\n\nExplain how to find equilibrium price and quantity from supply and demand equations.\nExample: Solve for equilibrium point using a supply and demand equation.\nExercise: Calculate equilibrium price and quantity for different scenarios.\n\n\nShifts in Supply and Demand\n\nFactors Causing Shifts in Supply and Demand Curves\n\nIdentify factors that can lead to shifts in supply and demand curves.\nDiscuss examples such as changes in consumer preferences or technological advancements.\nExercise: Identify possible shifts due to external factors.\n\nEffects on Equilibrium Price and Quantity\n\nExplain how shifts affect equilibrium price and quantity.\nDiscuss scenarios of price increases, decreases, and quantity changes.\nExample: Analyze the impact of a decrease in production costs on equilibrium.\nExercise: Predict the outcomes of shifts in supply and demand curves.\n\n\nApplications to Real-World Scenarios\n\nApplying Supply and Demand Analysis to Real-World Scenarios\n\nPresent scenarios like price ceilings, shortages, and surpluses.\nDiscuss the implications of government interventions on markets.\nExercise: Analyze the effects of a price ceiling on a graph.\n\nUnderstanding Market Dynamics and Changes\n\nEmphasize the importance of understanding supply and demand dynamics in decision-making.\nDiscuss how businesses and policymakers use these concepts.\nExample: Explain how supply and demand analysis can help plan for seasonal products.\n\n\nConclusion and Recap\n\nSummarize the key concepts covered in the lecture.\n\nQ&A Session"
  },
  {
    "objectID": "Teaching/Pre-sessionals/Stats2.html",
    "href": "Teaching/Pre-sessionals/Stats2.html",
    "title": "Pre-sessionals - Stats 2",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInternet is a great resource. Use it. Some resources I like:\n\nMIT OpenCourseWare,\nStanford,\nHarvard.\n\n\n\n\n\n\n\n\n\n\nBeware, the Crime!\n\n\n\nIt is illegal to download articles and books from pages like LibGen, Sci-hub or from Telegram bots like @scihubot. Also, DO NOT use VPN to protect your freedom of education (Opera offers a free VPN).\n\n🙃\n\n\n\n\n\n\nExploring Data and Plots\n\n\nHistograms and Frequency Distributions\n\nCreating Histograms\n\nDefine histograms as graphical representations of data distributions.\nExplain the concept of bins and their role in constructing histograms.\nExample: Create a histogram for a set of exam scores.\nExercise: Construct a histogram for a given dataset.\n\nUnderstanding Frequency Distributions\n\nDefine frequency distributions as tables summarizing data frequency.\nExplain how to organize data into intervals and record frequencies.\nExample: Create a frequency distribution table for a dataset.\nExercise: Create frequency distribution tables for various datasets.\n\nChoosing Appropriate Bin Sizes\n\nDiscuss considerations for selecting bin sizes in histograms.\nExplain the trade-off between too few and too many bins.\nExercise: Determine suitable bin sizes for different datasets.\n\n\nBar Plots and Pie Charts\n\nConstructing Bar Plots for Categorical Data\n\nDefine bar plots as visual representations of categorical data.\nExplain how to create vertical and horizontal bar plots.\nExample: Construct a bar plot for survey responses.\nExercise: Create bar plots for given categorical data.\n\nInterpreting Pie Charts\n\nDefine pie charts as circular representations of parts of a whole.\nExplain how to calculate angles and percentages for each category.\nExample: Interpret a pie chart depicting distribution of expenses.\nExercise: Interpret and analyze pie charts.\n\nUse Cases and Limitations of Each Plot\n\nDiscuss when to use bar plots and pie charts based on data characteristics.\nHighlight limitations and potential misinterpretations of these plots.\nExercise: Determine which plot is more suitable for a given dataset.\n\n\nBox Plots (Box-and-Whisker Plots)\n\nDefinition and Components of a Box Plot\n\nDefine box plots as visualizations of the five-number summary.\nExplain the components: median, quartiles, whiskers, and outliers.\nExample: Describe the features of a box plot.\nExercise: Identify components of box plots from provided data.\n\nCreating Box Plots for Numerical Data\n\nExplain how to create a box plot using numerical data.\nDiscuss the process of identifying quartiles and outliers.\nExample: Create a box plot for a dataset of test scores.\nExercise: Construct box plots for given numerical datasets.\n\nIdentifying Median, Quartiles, Outliers, and Range\n\nDemonstrate how to locate median, quartiles, and outliers on a box plot.\nExplain how to calculate the interquartile range (IQR).\nExercise: Analyze box plots and calculate IQR for different datasets.\n\n\nScatter Plots and Correlation\n\nCreating Scatter Plots\n\nDefine scatter plots as representations of relationships between two numerical variables.\nExplain how to plot data points and interpret patterns.\nExample: Create a scatter plot for height and weight data.\nExercise: Create scatter plots for various pairs of numerical variables.\n\nPositive, Negative, and No Correlation\n\nDefine positive, negative, and no correlation between variables.\nExplain how to visually identify correlation patterns in scatter plots.\nExample: Interpret the correlation between study hours and exam scores.\nExercise: Determine correlation types in given scatter plots.\n\nCalculating and Interpreting Correlation Coefficients\n\nDefine the correlation coefficient and its range.\nExplain how to calculate and interpret correlation coefficients.\nExample: Calculate and interpret the correlation coefficient for a dataset.\nExercise: Calculate correlation coefficients and analyze their meanings.\n\n\nConclusion and Recap\n\nSummarize the key concepts covered in the lecture.\n\nQ&A Session\nReference: Statistics for Business, 2nd edition. R. A. Stine, D. Foster"
  },
  {
    "objectID": "Teaching/FM250.html",
    "href": "Teaching/FM250.html",
    "title": "FM250 (Finance)",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInternet is a great resource. Use it. Some resources I like:\n\nMIT OpenCourseWare,\nStanford,\nHarvard.\n\n\n\n\n\n\n\n\n\n\nBeware, the Crime!\n\n\n\nIt is illegal to download articles and books from pages like LibGen, Sci-hub or from Telegram bots like @scihubot. Also, DO NOT use VPN to protect your freedom of education (Opera offers a free VPN).\n\n🙃\n\n\n\n\n\n\nCourse content (Official)\n\n\nNet Present Value technique,\nIntroduction to portfolio theory,\nThe Capital Asset Pricing Model (CAPM),\nStock market efficiency,\nForward and futures contracts, option pricing,\nInvestment decisions and the significance of real options,\nCapital structure and dividend decisions,\nCapital restructuring: Initial Public Offering.\n\n\nNotes of the material (Partially mine)\n\nHere are some notes that I took during the course (and I used to teach).\n\n\n\nDay\nPersonal notes\n\n\n\n\n\n\n\nDay 1\nNotes 1\n\n\n\n\n\nDay 2\nNotes 2\n\n\n\n\n\nDay 3\nNotes 3\n\n\n\n\n\nDay 4\nNotes 4\n\n\n\n\n\nDay 5\nNotes 5\n\n\n\n\n\nDay 6\nExam\n\n\n\n\n\nDay 7\nNotes 7\n\n\n\n\n\nDay 8\nNotes 8\n\n\n\n\n\nDay 9\nNotes 9\n\n\n\n\n\nDay 10\nNotes 10\n\n\n\n\n\nDay 11\nNotes 11\n\n\n\n\n\nDay 12\nNotes 12"
  },
  {
    "objectID": "Teaching/ME306.html",
    "href": "Teaching/ME306.html",
    "title": "ME306 (Real Analysis)",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInternet is a great resource. Use it. Some resources I like:\n\nMIT OpenCourseWare,\nStanford,\nHarvard.\n\n\n\n\n\n\n\n\n\n\nBeware, the Crime!\n\n\n\nIt is illegal to download articles and books from pages like LibGen, Sci-hub or from Telegram bots like @scihubot. Also, DO NOT use VPN to protect your freedom of education (Opera offers a free VPN).\n\n🙃\n\n\n\n\n\nI do not have anymore any material I created during the teaching of this course. I can quote however the course overview. Because the material is quite basic, I don’t think it’s worth the effort to go and try to find more details about what was done and taught.\n\nCourse content (Official)\n\nThe course provides a rigorous, but accessible, treatment of real analysis and analysis on metric spaces and will be delivered by formal lectures supported by interactive classes.\n\nBasics: proof, logic, sets and functions,\nReal numbers and sequences,\nFunctions, limits and continuity,\nInfinite series,\nMetric and normed spaces,\nConvergence, completeness and compactness,\nContinuity in metric spaces,\nThe derivative,\nConvexity,\nFixed point theorems."
  },
  {
    "objectID": "Teaching/MA102_MA103.html",
    "href": "Teaching/MA102_MA103.html",
    "title": "MA102 - MA103 (Introduction to Abstract Mathematics)",
    "section": "",
    "text": "Contact\n\n\n\n\nName: Domenico Mergoni\nEmail: d.mergoni -at- lse.ac.uk\nWork: London School of Economics\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInternet is a great resource. Use it. Some resources I like:\n\nMIT OpenCourseWare,\nStanford,\nHarvard.\n\n\n\n\n\n\n\n\n\n\nBeware, the Crime!\n\n\n\nIt is illegal to download articles and books from pages like LibGen, Sci-hub or from Telegram bots like @scihubot. Also, DO NOT use VPN to protect your freedom of education (Opera offers a free VPN).\n\n🙃\n\n\n\n\n\n\nCourse content (Official)\n\nThe course is an introduction to the use of formal definitions and proofs in mathematics, and to basic results of elementary set theory, number theory, linear algebra, algebra and analysis. Specific topics covered are as follows: Logic, sets and functions, relations, real numbers, infimum and supremum, sequences, limits and continuity, integers, prime numbers, greatest common divisor and modular arithmetic, complex numbers, groups and vector spaces.\n\nPersonal notes (survived)\n\nHere are the notes that survived in my OneNote.\n\n\n\nWeek\nNotes\n\n\n\n\nWeek 1\nMy solutions\n\n\nWeek 2\nMy solutions\n\n\nWeek 3\nMy solutions\n\n\nWeek 4\nMy solutions\n\n\nWeek 5\nMy solutions\n\n\nWeek 7\nMy solutions\n\n\nWeek 10\nMy solutions"
  },
  {
    "objectID": "Teaching/Pre-sessionals.html",
    "href": "Teaching/Pre-sessionals.html",
    "title": "Pre-sessionals for Management",
    "section": "",
    "text": "This Pre-sessional course consists of two section, four hours each. In the first section, we are gonig to see an introduction to fundamental mathematical tools, in the second, we are going to examin fundamentals of statistics.\nA summary of the course is as follows:\n\nVery genericMathsStatistics\n\n\n\nMaths\n\n\nIntroduction to Functions and Linear Equations\nIntroduction to Derivatives\nSystems of Linear Equations\nSupply and Demand Problems\n\n\nStatistics\n\n\nIntroduction to Basic Statistics\nExploring Data and Plots\nProbability and Reading Table\n\n\n\n\nMaths\n\nLecture 1: Introduction to Functions and Linear Equations (1 hour)\n\nIntroduction to Functions:\n\nWhat is a function?\nDomain and range of a function.\nNotation: \\(f(x)\\), domain, range, etc.\n\nLinear Functions:\n\nDefinition of linear functions.\nGraphing linear functions.\nFinding the slope and \\(y\\)-intercept.\nWriting equations in slope-intercept form: \\(y = mx + b\\).\n\nPolynomial Functions of Degree 2:\n\nDefinition of polynomial functions.\nQuadratic functions: \\(f(x) = ax^2 + bx + c\\).\nGraphing quadratic functions.\nFinding the vertex, axis of symmetry, and intercepts.\n\nApplications of Functions:\n\nReal-world examples of functions.\nModeling with linear and quadratic functions.\nSimple problems involving functions.\n\n\nLecture 2: Introduction to Derivatives (1 hour)\n\nIntroduction to Derivatives:\n\nWhat is a derivative?\nThe concept of instantaneous rate of change.\nNotation: \\(f'(x)\\), \\(df/dx\\).\n\nDerivatives of Linear and Quadratic Functions:\n\nFinding the derivative of linear functions.\nFinding the derivative of quadratic functions.\nTangent lines and rates of change.\n\nBasic Rules of Differentiation:\n\nPower rule for differentiation.\nConstant rule and sum rule.\nDifferentiating polynomial functions.\n\nApplications of Derivatives:\n\nFinding maxima and minima using derivatives.\nTangent lines as approximations.\nSimple optimization problems.\n\n\nLecture 3: Systems of Linear Equations (1 hour)\n\nIntroduction to Systems of Equations:\n\nWhat is a system of equations?\nMethods for solving systems: graphing, substitution, elimination.\n\nGraphical Solution:\n\nSolving systems graphically.\nInterpreting solutions on graphs.\n\nSubstitution and Elimination Methods:\n\nSolving systems using substitution method.\nSolving systems using elimination (addition) method.\n\nApplications of Systems of Equations:\n\nReal-world examples of systems.\nUsing systems to solve practical problems (e.g., mixtures, interest).\n\n\nLecture 4: Supply and Demand Problems (1 hour)\n\nIntroduction to Supply and Demand:\n\nBasic concepts of supply and demand.\nEquilibrium point and market equilibrium.\n\nSupply and Demand Equations:\n\nModeling supply and demand using linear equations.\nEquilibrium price and quantity.\n\nShifts in Supply and Demand:\n\nFactors causing shifts in supply and demand curves.\nEffects on equilibrium price and quantity.\n\nApplications to Real-World Scenarios:\n\nApplying supply and demand analysis to real-world scenarios (e.g., price ceilings, shortages, surpluses).\nUnderstanding market dynamics and changes.\n\n\n\n\n\nStatistics\n\nLecture 1: Introduction to Basic Statistics (2 hours)\n\nIntroduction to Statistics:\n\nWhat is statistics and its importance.\nDescriptive vs. inferential statistics.\nTypes of data: categorical and numerical.\n\nMeasures of Central Tendency:\n\nMean, median, and mode.\nCalculating and interpreting each measure.\nReal-world examples.\n\nMeasures of Dispersion:\n\nRange, variance, and standard deviation.\nInterpreting variability.\nVariance and standard deviation for populations vs. samples.\n\nQuantiles and Percentiles:\n\nDefinition of quantiles and percentiles.\nCalculation and interpretation.\nBox plots and their use in visualizing quantiles.\n\n\nLecture 2: Exploring Data and Plots (1 hour)\n\nHistograms and Frequency Distributions:\n\nCreating histograms.\nUnderstanding frequency distributions.\nChoosing appropriate bin sizes.\n\nBar Plots and Pie Charts:\n\nConstructing bar plots for categorical data.\nInterpreting pie charts.\nUse cases and limitations of each plot.\n\nBox Plots (Box-and-Whisker Plots):\n\nDefinition and components of a box plot.\nCreating box plots for numerical data.\nIdentifying median, quartiles, outliers, and range.\n\nScatter Plots and Correlation:\n\nCreating scatter plots.\nPositive, negative, and no correlation.\nCalculating and interpreting correlation coefficients.\n\n\nLecture 3: Probability and Reading Tables (1 hour)\n\nIntroduction to Probability:\n\nBasic concepts of probability.\nProbability as a ratio.\nProbability vs. odds.\n\nProbability Distributions:\n\nDiscrete vs. continuous probability distributions.\nProbability mass function (PMF) and probability density function (PDF).\nExamples: uniform, binomial, and normal distributions.\n\nReading Data Tables:\n\nUnderstanding data tables and formats.\nExtracting information from frequency tables.\nInterpreting data presented in tabular form.\n\n\n\n\n\n\nAssessmentsMathsStatistics\n\n\nYou can find here some questions that will assess your previous knowledge of these topics. Do not worry if you cannot answer these, as we will go through the knowledge required to answer them during the lectures.\n\n\nPre-Lecture Assessment: Mathematics Knowledge Check\n\nWhich of the following equations represents a quadratic function?\n\n\\(y = 3x + 2\\)\n\\(y = x^3 - 2x\\)\n\\(y = 2x - 5\\)\n\\(y = 4x^2 - 7x + 1\\)\n\nWhat is the y-intercept of the linear function \\(y = 2x - 3\\)?\n\n\\((2, -3)\\)\n\\((-2, 3)\\)\n\\((0, -3)\\)\n\\((0, 2)\\)\n\nIf \\(f(x) = 4x^3 - 2x^2 + 7x - 1\\), what is the derivative \\(f'(x)\\)?\n\n\\(12x^2 - 4x + 7\\)\n\\(12x^2 - 4x - 7\\)\n\\(12x^3 - 4x^2 + 7\\)\n\\(12x^3 - 4x^2 - 7\\)\n\nHow many solutions can a system of linear equations have if the lines are parallel and distinct?\n\nOne solution\nTwo solutions\nInfinite solutions\nNo solution\n\nSolve the quadratic equation for \\(x\\): \\(x^2 - 9 = 0\\).\n\n\\(x = -3\\)\n\\(x = 0\\)\n\\(x = 3\\)\n\\(x = \\pm 3\\)\n\nWhich of the following equations represents a vertical line?\n\n\\(y = 2x + 1\\)\n\\(x = -3\\)\n\\(y = x^2 - 4\\)\n\\(y = -2x\\)\n\nGiven the system of two equations: \\(2x + y = 5\\) and \\(3x + 2y = 8\\). What is the solution \\((x, y)\\)?\n\n\\((1, 3)\\)\n\\((2, 1)\\)\n\\((3, 2)\\)\n\\((-1, -3)\\)\n\nWhat is the slope of the line passing through the points \\((2, 4)\\) and \\((4, 8)\\)?\n\n\\(2\\)\n\\(4\\)\n\\(1/2\\)\n\\(1\\)\n\nWhat is the mean of the numbers \\(5, 8, 10, 12\\), and \\(15\\)?\n\n\\(8\\)\n\\(10\\)\n\\(11\\)\n\\(12\\)\n\n\n\n\nPre-Lecture Assessment: Statistics Knowledge Check\n\nWhat is the mean of the numbers 5, 8, 10, 12, and 15?\n\n8\n10\n11\n12\n\nIf the range of a data set is 20 and the smallest value is 5, what is the largest value?\n\n20\n25\n15\n10\n\nWhich statistical measure is most affected by outliers?\n\nMean\nMedian\nMode\nRange\n\nWhat is the purpose of a scatter plot?\n\nTo display categorical data.\nTo show the relationship between two numerical variables.\nTo represent the distribution of a single variable.\nTo compare different groups of data.\n\nWhich of the following represents a positively skewed distribution?\n\nMean &lt; Median\nMean &gt; Median\nMean = Median\nNo relationship between Mean and Median\n\nWhat does a correlation coefficient of -0.85 indicate?\n\nStrong positive correlation\nModerate negative correlation\nWeak positive correlation\nStrong negative correlation\n\nIf two events are independent, what is the probability of both events occurring?\n\nP(A and B) = P(A) + P(B)\nP(A and B) = P(A) * P(B)\nP(A and B) = P(A) - P(B)\nP(A and B) = P(A) / P(B)\n\nWhat is the main purpose of calculating quantiles in statistics?\n\nTo find the mean of the data.\nTo identify the median of the data.\nTo measure the spread of the data.\nTo divide the data into equal parts.\n\nWhat is the difference between variance and standard deviation?\n\nVariance is the square root of standard deviation.\nVariance measures spread, while standard deviation measures average deviation.\nVariance is always positive, while standard deviation can be negative.\nVariance is used for categorical data, while standard deviation is used for numerical data.\n\nIn a normal distribution, what percentage of data falls within one standard deviation from the mean?\n\nApproximately 34%\nApproximately 68%\nApproximately 95%\nApproximately 99.7%"
  }
]